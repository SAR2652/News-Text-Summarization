{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SAR2652/BBC-News-Text-Summarization/blob/main/BBC_News_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKeo7Ubmw4WN"
   },
   "source": [
    "# News Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 16:38:33.491962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-07 16:38:33.492193: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_validation, ds_test), ds_info = tfds.load('multi_news', shuffle_files = True, split = ['train', 'validation', 'test'], with_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 16:38:35.063428: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-07 16:38:35.063840: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Nicki Minaj attends the Harper\\'s BAZAAR \"IC...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 Nicki Minaj and Cardi B were in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'COLUMBIA, S.C. Federal authorities launched ...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 A police officer in Columbia, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"In Brief \\n  \\n San Francisco named top U.S....</td>\n",
       "      <td>b'\\xe2\\x80\\x93 San Francisco has topped this y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'About 1 in 45 children in the United States ...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 A new report reveals what appea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'A day after allegations surfaced that Northa...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 The head coach and assistant co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  b'Nicki Minaj attends the Harper\\'s BAZAAR \"IC...   \n",
       "1  b'COLUMBIA, S.C. Federal authorities launched ...   \n",
       "2  b\"In Brief \\n  \\n San Francisco named top U.S....   \n",
       "3  b'About 1 in 45 children in the United States ...   \n",
       "4  b'A day after allegations surfaced that Northa...   \n",
       "\n",
       "                                             summary  \n",
       "0  b'\\xe2\\x80\\x93 Nicki Minaj and Cardi B were in...  \n",
       "1  b'\\xe2\\x80\\x93 A police officer in Columbia, S...  \n",
       "2  b'\\xe2\\x80\\x93 San Francisco has topped this y...  \n",
       "3  b'\\xe2\\x80\\x93 A new report reveals what appea...  \n",
       "4  b'\\xe2\\x80\\x93 The head coach and assistant co...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = tfds.as_dataframe(ds_train.take(-1), ds_info)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'CLOSE SportsPulse: NFL Insider Mike Jones po...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 The Kansas City Chiefs learned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'Can\\xe2\\x80\\x99t go to space? Try Idaho. Las...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 There are fewer than a dozen da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Oscar de la Renta was a great man, and a gre...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 Fashion designer and icon Oscar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'With his first trip abroad as president behi...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 \"I think we hit a home run,\" Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'7 Gallery: Jessica Heeringa, missing from Ex...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 Jessica Heeringa was working th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  b'CLOSE SportsPulse: NFL Insider Mike Jones po...   \n",
       "1  b'Can\\xe2\\x80\\x99t go to space? Try Idaho. Las...   \n",
       "2  b'Oscar de la Renta was a great man, and a gre...   \n",
       "3  b'With his first trip abroad as president behi...   \n",
       "4  b'7 Gallery: Jessica Heeringa, missing from Ex...   \n",
       "\n",
       "                                             summary  \n",
       "0  b'\\xe2\\x80\\x93 The Kansas City Chiefs learned ...  \n",
       "1  b'\\xe2\\x80\\x93 There are fewer than a dozen da...  \n",
       "2  b'\\xe2\\x80\\x93 Fashion designer and icon Oscar...  \n",
       "3  b'\\xe2\\x80\\x93 \"I think we hit a home run,\" Pr...  \n",
       "4  b'\\xe2\\x80\\x93 Jessica Heeringa was working th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = tfds.as_dataframe(ds_validation.take(-1), ds_info)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Think back, everyone -- can you remember whe...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 No matter how much you like Jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"'Alien: Covenant': Film Review \\n  \\n Michae...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 A spaceship arrives on a distan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'By REUTERS \\n  \\n Photo: Reuters \\n  \\n Char...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 France is on lockdown today aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'These crawls are part of an effort to archiv...</td>\n",
       "      <td>b\"\\xe2\\x80\\x93 Just when you thought the Repub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'The estranged wife of acclaimed concert pian...</td>\n",
       "      <td>b'\\xe2\\x80\\x93 Sofya Tsygankova, the estranged...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  b'Think back, everyone -- can you remember whe...   \n",
       "1  b\"'Alien: Covenant': Film Review \\n  \\n Michae...   \n",
       "2  b'By REUTERS \\n  \\n Photo: Reuters \\n  \\n Char...   \n",
       "3  b'These crawls are part of an effort to archiv...   \n",
       "4  b'The estranged wife of acclaimed concert pian...   \n",
       "\n",
       "                                             summary  \n",
       "0  b'\\xe2\\x80\\x93 No matter how much you like Jas...  \n",
       "1  b'\\xe2\\x80\\x93 A spaceship arrives on a distan...  \n",
       "2  b'\\xe2\\x80\\x93 France is on lockdown today aft...  \n",
       "3  b\"\\xe2\\x80\\x93 Just when you thought the Repub...  \n",
       "4  b'\\xe2\\x80\\x93 Sofya Tsygankova, the estranged...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = tfds.as_dataframe(ds_test.take(-1), ds_info)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(x):\n",
    "    return x.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 44972/44972 [00:00<00:00, 102601.53it/s]\n",
      "100%|█████████████████████████████████| 44972/44972 [00:00<00:00, 555703.24it/s]\n",
      "100%|███████████████████████████████████| 5622/5622 [00:00<00:00, 113006.99it/s]\n",
      "100%|███████████████████████████████████| 5622/5622 [00:00<00:00, 479607.39it/s]\n",
      "100%|███████████████████████████████████| 5622/5622 [00:00<00:00, 110315.49it/s]\n",
      "100%|███████████████████████████████████| 5622/5622 [00:00<00:00, 521320.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train.loc[:, 'document'] = df_train.loc[:, 'document'].progress_apply(decode_text)\n",
    "df_train.loc[:, 'summary'] = df_train.loc[:, 'summary'].progress_apply(decode_text)\n",
    "df_val.loc[:, 'document'] = df_val.loc[:, 'document'].progress_apply(decode_text)\n",
    "df_val.loc[:, 'summary'] = df_val.loc[:, 'summary'].progress_apply(decode_text)\n",
    "df_test.loc[:, 'document'] = df_test.loc[:, 'document'].progress_apply(decode_text)\n",
    "df_test.loc[:, 'summary'] = df_test.loc[:, 'summary'].progress_apply(decode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrZKl4-zxOjs"
   },
   "source": [
    "## Prepare Environment for Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_piYKrawuML"
   },
   "source": [
    "## Extractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yd4WBs-wO97"
   },
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onMTbQltZSJX",
    "outputId": "5a94ba40-1453-4f31-9898-29546b738b42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sarvesh26/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sarvesh26/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, heapq, nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDQJb0KrwUtQ"
   },
   "source": [
    "### Function for Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9U_5Sbu7WEHK"
   },
   "outputs": [],
   "source": [
    "def extractive_summarize(text):\n",
    "    # Tokenization\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Text preprocessing\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', text) # remove numeric citations\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove 1+ continuous whitespaces\n",
    "    clean_text = text.lower() # convert all text to lower case\n",
    "    clean_text = re.sub(r'\\W', ' ', clean_text) # remove non-word characters\n",
    "    clean_text = re.sub(r'\\d', ' ', clean_text) # remove any digits\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text) # remove 1+ continuous whitespaces\n",
    "\n",
    "    # Generate dictionary of word frequencies while deleting stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    word2count = {}\n",
    "    for word in nltk.word_tokenize(clean_text):\n",
    "        if word not in stop_words:\n",
    "            if word not in word2count.keys(): # create new key as word\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "\n",
    "    # standardize all values\n",
    "    for key in word2count.keys():\n",
    "        word2count[key] = word2count[key] / max(word2count.values())\n",
    "\n",
    "    # Generate information\n",
    "    sent2score = {}\n",
    "    for sentence in sentences:\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word in word2count.keys():\n",
    "                if len(sentence.split(' ')) < 30:   # sentence length condition\n",
    "                    if sentence not in sent2score.keys():\n",
    "                        sent2score[sentence] = word2count[word]\n",
    "                    else:\n",
    "                        sent2score[sentence] += word2count[word]\n",
    "\n",
    "    # Select best sentences\n",
    "    best_sentences = heapq.nlargest(5, sent2score, key = sent2score.get)\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    for sentence in best_sentences:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUkAY97TypaC"
   },
   "source": [
    "### Test for Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLOSE SportsPulse: NFL Insider Mike Jones ponders why it took a TMZ video for the Chiefs to make the right call and where the league and Kareem Hunt go from here. USA TODAY \\n  \\n Kansas City Chiefs running back Kareem Hunt (27) runs the ball during the game against the Arizona Cardinals at Arrowhead Stadium. The Chiefs won 26-14. (Photo: Denny Medley, USA TODAY Sports) \\n  \\n Video published Friday shows Kansas City Chiefs star running back Kareem Hunt getting into a physical altercation with a woman in which he shoves her, charges at her and kicks her in the hallway of a Cleveland apartment building. \\n  \\n Hunt was released by the Chiefs later on Friday, with team saying the player \"was not truthful\" in discussions about the incident. \\n  \\n The incident took place Feb. 10, according to police reports obtained by USA TODAY Sports. The video, published by TMZ, appears to be security footage from inside the apartment building. Hunt was not charged. \\n  \\n Hunt can be seen approaching the woman and engaging in a verbal argument before shoving her back with his right hand. Another man tries to restrain Hunt, while the woman approaches him and swats at Hunt’s face, making contact. \\n  \\n The video then shows multiple people restraining Hunt as he tries to free himself and charge toward her. Then, after the situation appeared to be defused, another man restrains the woman before Hunt barrels through the hallway, knocking into the man and the woman, sending them tumbling to the ground. \\n  \\n After being knocked to the ground, the woman appears to be disoriented and tries to collect herself. While she is kneeling near the ground, Hunt walks over and kicks her with his right foot. \\n  \\n Police responded to the luxury apartment and hotel building after a woman told 911 operators she was assaulted. Once on the scene, police interviewed two of the alleged victims, one stating that she had been assaulted “by a player” after the two were asked to leave the apartment belonging to Hunt,” according to the police reports obtained. \\n  \\n “Kareem, is his name,” one of the alleged victims told police in bodycam footage obtained by TMZ. “I just met him today. He shoved me. He pushed me. ... Kareem, the person who assaulted me, had my phone. I had no way of calling (police).” \\n  \\n Rayshawn Watkins, Hunt’s friend, friend told police that the accuser began calling both him and Hunt the “N-word” after the two were asked to leave the room once they found out both women were 19 years old. The two then pounded on the door of the apartment “about 20 times,” Watkins told police. \\n  \\n Cuyahoga County Prosecutor’s Office spokesperson Ryan Miday told USA TODAY Sports that the office – which typically only handles felony cases – is not currently pursuing charges against Hunt. A search of the Cleveland Municipal Court online database does not show any pending case involving Hunt. \\n  \\n \"I want to apologize for my actions,\" Hunt said in a statement to ESPN and NFL Network. \"I deeply regret what I did. I hope to move on from this.\" \\n  \\n The NFL on Friday placed Hunt on the commissioner\\'s exempt list, preventing him from practicing as well as playing in and attending games. \\n  \\n Hunt has not missed any games and had been an integral part of Kansas City’s success, rushing the ball 181 times for 824 yards and seven touchdowns, while adding 26 catches for 378 yards and seven more receiving scores. \\n  \\n CLOSE Listen to the 911 call reporting the violent altercation between Kansas City Chiefs running back Kareem Hunt and a woman at a Cleveland hotel in February. USA TODAY \\n  \\n During training camp in August, Chiefs owner Clark Hunt addressed the incident \\n  \\n “The team’s made up of a bunch of young men,” Hunt said Aug. 4, according to the Kansas City Star. “They’re not always going to make the best decisions, but we have a strong support system, both with the coaching staff and also with our player development department that works with young guys and talks to them about the situations that they want to be in. \\n  \\n “Kareem is a young man, second year in the league, obviously had a very big year on the field last year. I’m sure he learned some lessons this offseason and hopefully won’t be in those kind of situations in the future.” \\n  \\n Clark Hunt later added that he didn’t expect the running back to be suspended. \\n  \\n According to the Star, Kareem Hunt said at the time of the incident: “I’ve learned from it and I’m focused on football.” \\n  \\n When questioned further, he offered little more. \\n  \\n “Just be in the right place at the right time,” Hunt said. “I’m going to keep thinking about football and go out there and do my job.” \\n  \\n Cleveland police spokesperson Jennifer Ciaccia told USA TODAY Sports in email that the \"city did not release surveillance video\" TMZ posted. Ciaccia did not immediately respond when asked if police viewed the footage before Friday. \\n  \\n Domestic violence came to the forefront in the NFL in 2014 when video obtained by TMZ showed former Baltimore Ravens running back Ray Rice knocking out his then-fiancée in an elevator in an Atlantic City hotel in February. \\n  \\n The NFL suspended Rice for two games in June 2014. However the league was criticized for the light penalty after the video became public in September. Commissioner Roger Goodell then announced that Rice would be suspended indefinitely. \\n  \\n Rice later appealed, and then won, vacating the lengthier suspension. He was cut by the Ravens and never played in the NFL again. ||||| Kareem Hunt Cut by the Chiefs for Brutalizing Woman on Video ... Team Says He Lied \\n  \\n KC Chiefs Release Kareem Hunt Over Video of Him Brutalizing Woman \\n  \\n EXCLUSIVE \\n  \\n 6:27 PM PT -- Hunt just made a statement to ESPN about our video, saying, \"I want to apologize for my actions. I deeply regret what I did. I hope to move on from this.\" \\n  \\n 5:50 PM PT -- The Chiefs have cut Kareem Hunt, and say he lied to the team when they spoke directly to him about the incident. \\n  \\n The team says when the NFL and Cleveland PD launched their investigations the team called in Hunt and \"several members of our management team spoke directly to him. Kareem was not truthful in those discussions. The video released today confirms that fact.\" \\n  \\n A source connected to the NFL investigation tells TMZ ... the league made multiple attempts to obtain the video, but was turned away. We\\'re told the league contacted the hotel, and was told it is corporate policy to only turn surveillance video over to law enforcement. \\n  \\n We contacted the Metropolitan at The 9 and COO Tony Quintal says, \"We realize that this is an ongoing investigation and cannot share any additional information at this time.\" \\n  \\n We\\'re told the NFL also contacted Cleveland PD attempting to get the video, but was also denied. The source says the league\\'s investigation included reaching out to the alleged victim, who did not respond. \\n  \\n 5:26 PM PT -- The NFL just announced Hunt\\'s been placed on the commissioner exempt list and will NOT practice, play or attend games. The NFL added, \"The NFL\\'s investigation, which began immediately following the incident in February, will include a review of the new information that was made public today.\" \\n  \\n 1:33 PM PT -- Hunt has reportedly been sent home from the Chiefs\\' practice facility, according to ESPN\\'s Dan Graziano. \\n  \\n He reports Hunt will likely be placed on the commissioner\\'s exempt list -- which means he will probably not play this Sunday when the Chiefs take on the Raiders in Oakland. \\n  \\n TMZ Sports has obtained video of Kansas City Chiefs star running back Kareem Hunt shoving, bull-rushing and kicking a woman in a Cleveland hotel back in February. \\n  \\n Kareem has not missed a single game this season despite the incident happening MONTHS before the 2018 NFL season kicked off ... and team CEO Clark Hunt publicly stated in August he doubted Hunt would be suspended. \\n  \\n In the video, Hunt is seen arguing with a 19-year-old woman outside of his room at The Metropolitan at the 9 at 3:22 AM on February 10, 2018. \\n  \\n Hunt turns a corner and confronts the woman, shoving her hard. The woman strikes him back in the face ... and that\\'s when Hunt goes berserk. \\n  \\n As friends try to hold him back, the 2017 Pro Bowler -- who led the league in rushing yards -- explodes and knocks one of his friends into the woman ... who both go flying into a wall. \\n  \\n Both Kareem\\'s male friend and the woman appear dazed -- but Kareem makes his way over to the female and kicks her while she\\'s crouching on the ground ... knocking her over. \\n  \\n Police were called to the scene but no arrests were made. According to police reports, obtained by TMZ Sports, surveillance video from the hotel was obtained by law enforcement. We\\'re told that video is part of the evidence that was submitted to prosecutors. \\n  \\n Still, cops did not arrest Hunt and no charges were filed because officers say they were unable to determine if a crime had been committed. \\n  \\n At the time of the incident, the woman told police the whole thing started because Kareem kicked her out of his room after she refused to hook up with one of the men in Kareem\\'s entourage. \\n  \\n Kareem\\'s friends told cops the woman had gone crazy when asked to leave and called Kareem the n-word ... and then struck one of Kareem\\'s female friends once things turned physical. \\n  \\n Unclear why the NFL has not taken any action against Hunt. We reached out to the league to find out if they pursued the video. We also reached out to cops to find out if the NFL contacted them about the footage as well. \\n  \\n The whole incident is reminiscent of the Ray Rice scandal when the NFL star knocked out his then-fiancee in a hotel elevator in Feb. 2014. \\n  \\n The NFL suspended him indefinitely -- but only after TMZ Sports published the brutal knockout video from inside the elevator ... video the NFL claimed they had not seen until our story. \\n  \\n After the incident, NFL commissioner Roger Goodell acknowledged failures in the NFL\\'s investigative process and said they would overhaul their protocol. \\n  \\n Since then, the NFL claims it has tried to be tougher on players accused of attacking women -- most famously, the league suspended Ezekiel Elliott for 6 games in 2017 stemming from allegations he got physical with an ex-girlfriend in 2016. \\n  \\n We reached out to the NFL for comment -- so far, no word back. \\n  \\n Originally Published -- 11:33 AM PST ||||| Running back Kareem Hunt was released by the Chiefs hours after video footage published Friday showed him shoving and kicking a woman in a hallway. \\n  \\n “Earlier this year, we were made aware of an incident involving running back Kareem Hunt,” read a statement issued by the Chiefs on Friday night. “At that time, the National Football League and law enforcement initiated investigations into the issue. As part of our internal discussions with Kareem, several members of our management team spoke directly to him. Kareem was not truthful in those discussions. The video released today confirms that fact. We are releasing Kareem immediately.” \\n  \\n The video of Hunt, obtained and published by TMZ Sports, is related to a February 2018 altercation on an early Saturday morning at The Metropolitan at the 9, Hunt’s hotel apartment in downtown Cleveland. Police were called and a written report was previously made, but video footage was not available until it was published by TMZ. \\n  \\n “I want to apologize for my actions,” Hunt said in a statement to ESPN. “I deeply regret what I did. I hope to move on from this.” \\n  \\n Premium content for only $0.99 For the most comprehensive local coverage, subscribe today. \\n  \\n In response to an email from The Star inquiring about the NFL’s knowledge of the video, NFL spokesman Brian McCarthy said, “Neither the NFL nor the Chiefs viewed the video before it became public today.” \\n  \\n According to a source with knowledge of the NFL’s investigation, the hotel told NFL representatives that it could only give video to law enforcement under corporate policy; the NFL contacted the Cleveland Police Department, which did not provide the NFL any video; and the NFL contacted the alleged victims, who did not respond to multiple messages. \\n  \\n Minutes before the Chiefs took action, the NFL said Hunt, who led the league in rushing as a rookie last season, had been placed on the NFL’s Commissioner Exempt List and that it “will include a review of the new information made public today” in the investigation it first opened in February. Hunt cannot practice or play in games for any NFL team while on the exempt list. \\n  \\n In the video, Hunt is seen coming out of a room and talking to a woman off camera. When she approached Hunt, he shoved her, and she hit him in the face. When another man came out of the hotel room and tried to intervene, Hunt continued to lunge toward the woman. As more people came into the hallway, Hunt had to be restrained several times as he made advances toward the woman and other people. At one point, Hunt appeared to knock two people over with a shove, including the woman he initially shoved. At the end of the video, Hunt kicked the woman as she was crouched on the ground. \\n  \\n The Chiefs and NFL did not take any action against Hunt after the altercation was reported to police in February. Hunt fully participated in Friday’s practice and was in the locker room afterward. He was spotted leaving the Chiefs’ facility at 2 p.m in his vehicle. The video was posted by TMZ at 1:33 p.m. The NFL statement was issued around 7:30 p.m. and the Chiefs released him shortly before 8 p.m. \\n  \\n No charges have been filed stemming from the altercation, which occurred on Feb. 10, but two police reports were created. In one report, 19-year-old Abigail Ottinger is listed as a suspect, and in another Hunt is listed as a suspect. \\n  \\n Ottinger told police that Hunt “shoved and pushed her.” There was no mention of a kick in either police report or in police interviews with involved parties. \\n  \\n SHARE COPY LINK Bodycam video released by the Cleveland Police Department shows a woman allegedly assaulted by Kansas City Chiefs running back Kareem Hunt detailing her account of what happened at the Metropolitan at the 9 hotel in downtown Cleveland. \\n  \\n According to one of the police reports, Ottinger and a friend told police they were Kent State students and were traveling to Cleveland bars with Hunt and his friends on a party bus. According to the police reports, Ottinger and her friend went back to Hunt’s hotel apartment, and Hunt’s friend told police that he kicked the girls out of the apartment when he learned they were 19. Ottinger told police they were kicked out because she “didn’t want” one of the men in the group. The man was not specifically identified. According to Hunt’s friend in one of the reports, Ottinger called Hunt and his friends racial slurs when they were told to leave. Once outside of the room, the report says, Ottinger and her friend banged on the hotel door “about 20 times. Ottinger eventually sat down on the ground outside the room, according to the report, and that’s when Hunt and another friend came outside to tell them to “go home” and Hunt “shoved and pushed” her. \\n  \\n The description of the violence in the police reports is brief, but in one, the police report that “the pushing and shoving caused abrasions on her left knee, right hand and a scratch on (Ottinger’s) chest.” Also in the same report, Ottinger’s friend said “‘all the boys’ began ‘chasing’ (Ottinger) around and trying to ‘hit’ her.” According to the report, the friend tried to record the this when one of Hunt’s friends took the phone out of her hand. She said that when she went after him, someone grabbed her and she fell to the floor. \\n  \\n TMZ also published a 15-second body cam video Friday of a shirtless Hunt talking to police. \\n  \\n Hunt was also involved in another altercation in June when he allegedly punched a man in the face at an Ohio resort. Hunt was not arrested following that incident either. \\n  \\n SHARE COPY LINK Kansas City Chiefs running back Kareem Hunt speaks briefly on Aug. 4, 2018 during training camp in St. Joseph about his offseason incidents and what he\\'s learned. \\n  \\n Chiefs CEO Clark Hunt addressed Hunt’s offseason altercations during training camp. \\n  \\n “The team is made up of a bunch of young men,” Clark Hunt said at the Chiefs’ training camp before the season. “They’re not always going to make the best decisions, but we have a strong support system both with the coaching staff and with our player development department that works with young guys and talks to them about the situations that they want to be in. Kareem is a young man, second year in the league, obviously had a very big year on the field last year. I’m sure he learned some lessons this offseason and hopefully won’t be in those kinds of situations in the future.” \\n  \\n Asked at training camp about his offseason, Kareem Hunt didn’t elaborate much. \\n  \\n “Just be in the right place at the right time,” he said then. “I’m going to keep thinking about football and go out there and do my job.” \\n  \\n As a rookie last season, Hunt led the league in rushing with 1,327 yards. This year, Hunt has 824 yards and seven touchdowns. \\n  \\n The Star’s Lynn Worthy contributed to this report \\n  \\n Brooke Pryor Brooke Pryor covers the Kansas City Chiefs and NFL for The Star. ||||| FILE - In this Oct. 8, 2017, file photo, Kansas City Chiefs running back Kareem Hunt warms up for the team\\'s NFL football game against the Houston Texans in Houston. A person with knowledge of the move... (Associated Press) \\n  \\n FILE - In this Oct. 8, 2017, file photo, Kansas City Chiefs running back Kareem Hunt warms up for the team\\'s NFL football game against the Houston Texans in Houston. A person with knowledge of the move tells The Associated Press that Hunt appears headed to the NFL\\'s Commissioner Exempt List, sidelining... (Associated Press) \\n  \\n KANSAS CITY, Mo. (AP) — The Kansas City Chiefs released running back Kareem Hunt on Friday night after video surfaced that showed the NFL\\'s reigning rushing champion knocking over and kicking a woman in a Cleveland hotel hallway in February. \\n  \\n The team issued a statement shortly after the NFL had placed Hunt on its Commissioner Exemption List that said the running back lied when asked about the incident by team officials. The team said \"the video today confirms that fact. We are releasing Kareem immediately.\" \\n  \\n Hunt was at the Chiefs\\' facility earlier Friday in preparation for Sunday\\'s trip to Oakland, but he was excused and sent home shortly after TMZ posted the video online. It shows Hunt being restrained several times by friends before pushing a woman to the ground, where he proceeds to kick her. \\n  \\n Police were called to the scene during the Feb. 10 incident, no charges were filed. The police did not respond to several requests for comment Friday night. \\n  \\n \"Earlier this year, we were made aware of an incident involving running back Kareem Hunt. At that time, the National Football League and law enforcement initiated investigations into the issue,\" the Chiefs said. \"As part of our internal discussions with Kareem, several members of our management team spoke directly to him. Kareem was not truthful in those discussions.\" \\n  \\n The Chiefs and the NFL have been aware of Hunt\\'s incident since it occurred, but much like the case involving former Ravens running back Ray Rice, the shocking video brought a new dimension to the case. It showed Hunt lunging toward a woman and several others in the hotel hallway, and the second-year pro being restrained several times before knocking two people down. \\n  \\n While no charges were filed from the altercation, two police reports were created. Hunt is listed as the suspect in one of them and a woman, Abigail Ottinger, is the suspect in the other one. \\n  \\n Hunt also was involved in a June incident, according to TMZ, in which he allegedly punched a man at an Ohio resort. The man Hunt struck declined to press charges. \\n  \\n \"I want to apologize for my actions. I deeply regret what I did,\" Hunt said in a statement issued to several outlets shortly after he was released. \"I hope to move on from this.\" \\n  \\n When asked about the incidents in training camp, Hunt said \"I\\'ve learned from it.\" When asked to elaborate on what he learned, he replied: \"Just be in the right place at the right time.\" \\n  \\n Hunt led the NFL in rushing as a rookie with 1,327 yards and eight touchdowns in helping Kansas City make the playoffs. He had run for 824 yards this season, with seven touchdowns passing and seven more receiving, in helping the Chiefs to a 9-2 start and a stranglehold on the AFC West. \\n  \\n Spencer Ware is expected to take over as the lead running back. \\n  \\n Chiefs chairman Clark Hunt was asked several times about Hunt\\'s incidents in the offseason, and he acknowledged that \"young men are not always going to make the best decisions.\" \\n  \\n \"We have a strong support system, both with the coaching staff and also our player development that works with young guys and talks to them about the situations that they want to be in,\" Clark Hunt said during training camp. \"Obviously he had a very big year on the field last year. I\\'m sure he learned some lessons this offseason and hopefully won\\'t be in those kind of situations in the future.\" \\n  \\n He won\\'t be as a member of the Chiefs. \\n  \\n Domestic violence has been a major issue in the NFL in recent years, one that struck home in Kansas City in 2012 when Chiefs linebacker Jovan Belcher killed his girlfriend before killing himself at the team\\'s practice facility. Belcher was later found to have suffered from CTE. \\n  \\n The most memorable incident came in 2014, when a video showed Rice knocking out his then-fiancee in an elevator in an Atlantic City hotel. Rice was originally suspended two games by NFL Commissioner Roger Goodell, who later was heavily criticized for such a light penalty after the video was released. \\n  \\n Rice soon after was suspended indefinitely by the league. He won an appeal but was released by the Ravens, and the three-time Pro Bowl running back never returned to the NFL. \\n  \\n Last year, Cowboys running back Ezekiel Elliott was suspended for six games by Goodell after the league concluded following a yearlong investigation that he had several physical confrontations in the summer of 2016 with his girlfriend at the time. \\n  \\n The league has implemented a stronger domestic violence policy, but incidents have continued to make news. Just last weekend, the 49ers cut linebacker Reuben Foster when he was arrested on suspicion of domestic violence — he has since signed with Washington but remains on the NFL\\'s exempt list. \\n  \\n Hunt had exhibited a pattern of questionable behavior dating to his college days at Toledo, where he shattered school records but also was suspended his junior season for violating team rules. \\n  \\n The Chiefs chose him in the third round of last year\\'s NFL draft, and he was poised to spend the season as the backup before Ware went down with a season-ending knee injury in the preseason. Hunt was thrust into the starting role and fumbled on his very first carry in a game in New England, but bounced back to have one of the best seasons in franchise history. \\n  \\n He had six games of at least 100 yards rushing and helped Kansas City win consecutive division titles for the first time, a season that ultimately landed Hunt in the Pro Bowl. \\n  \\n Hunt was off to another good start this season, his rushing yardage putting him fourth in the NFL and his touchdown total trailing only the Rams\\' Todd Gurley II and the Saints\\' Alvin Kamara. \\n  \\n He was also well-liked in the locker room, despite the off-the-field distractions from this past offseason. Hunt had joined quarterback Patrick Mahomes, tight end Travis Kelce and several other Chiefs players in attending Sporting Kansas City\\'s playoff game on Thursday night. \\n  \\n ___ \\n  \\n More AP NFL: https://apnews.com/NFL and https://twitter.com/AP_NFL |||||'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = df_val['document'].values[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "TMZ Sports has obtained video of Kansas City Chiefs star running back Kareem Hunt shoving, bull-rushing and kicking a woman in a Cleveland hotel back in February.\n",
      "Ottinger told police that Hunt “shoved and pushed her.” There was no mention of a kick in either police report or in police interviews with involved parties.\n",
      "Hunt had joined quarterback Patrick Mahomes, tight end Travis Kelce and several other Chiefs players in attending Sporting Kansas City's playoff game on Thursday night.\n",
      "Chiefs chairman Clark Hunt was asked several times about Hunt's incidents in the offseason, and he acknowledged that \"young men are not always going to make the best decisions.\"\n",
      "It showed Hunt lunging toward a woman and several others in the hotel hallway, and the second-year pro being restrained several times before knocking two people down.\n"
     ]
    }
   ],
   "source": [
    "extractive_summarize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a6jyo6nxsLB"
   },
   "source": [
    "## Abstractive Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Dn4nuVjx7AV"
   },
   "source": [
    "### Import the remaining libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AwU_0UhZxzwV"
   },
   "outputs": [],
   "source": [
    "import os, string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import wordpunct_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, AdditiveAttention, Concatenate, TimeDistributed\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqwVbcd4O4Gm"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LoOLDJFmO2ah"
   },
   "outputs": [],
   "source": [
    "def length(x):\n",
    "    return len(wordpunct_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Typzy9X5OxB-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 44972/44972 [00:26<00:00, 1715.81it/s]\n",
      "100%|██████████████████████████████████| 44972/44972 [00:03<00:00, 13906.34it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['Article_Length'] = df_train['document'].progress_apply(length)\n",
    "df_train['Summary_Length'] = df_train['summary'].progress_apply(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcVd80eSQCbo"
   },
   "source": [
    "#### Examine the distribution of lengths together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9y-uoqNQm9W"
   },
   "source": [
    "##### Combined Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "vmVjaIhxOFM4",
    "outputId": "81eab08f-b674-4b75-edca-8d338c95a161"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d2933d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (13, 9))\n",
    "sns.distplot(df_train['Article_Length'], color = 'red', label = 'Article Length')\n",
    "sns.distplot(df_train['Summary_Length'], color = 'blue', label = 'Summary Length')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfdGMo3OQHwU"
   },
   "source": [
    "#### Examine the distribution of lengths separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tenLRF8aQRmB"
   },
   "source": [
    "##### Distribution Plot for Article Length as well as Statistical Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "uVj9huWrP_e1",
    "outputId": "5d3eded3-5608-4a06-ab43-16c2941a31c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Article_Length', ylabel='Density'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_train['Article_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzZDPC_DREM0",
    "outputId": "34cd8a0c-4b3b-448e-8274-3ef5225d24d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     44972.000000\n",
       "mean       2171.902161\n",
       "std        3694.544933\n",
       "min          27.000000\n",
       "25%         975.000000\n",
       "50%        1600.000000\n",
       "75%        2554.000000\n",
       "max      538078.000000\n",
       "Name: Article_Length, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Article_Length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFWtl5ZRo2oi",
    "outputId": "8d376dbb-ad6d-4334-a3c3-2bcfb5eb8814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4097.800000000003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(df_train['Article_Length'], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0us4ec3QuDP"
   },
   "source": [
    "##### Distribution Plot for Summary Length as well as Statistical Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "jmCgbyUhQuDQ",
    "outputId": "46edacb3-27f8-40e4-b6ae-2acf32afbeca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Summary_Length', ylabel='Density'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_train['Summary_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whwx4IlFQ8gD",
    "outputId": "0aeab91b-950b-4941-b725-0969ddd924b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44972.000000\n",
       "mean       266.942320\n",
       "std         83.695479\n",
       "min         42.000000\n",
       "25%        207.000000\n",
       "50%        269.000000\n",
       "75%        320.000000\n",
       "max       1247.000000\n",
       "Name: Summary_Length, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Summary_Length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwCqbTvEov59",
    "outputId": "6e082831-c7a3-48f0-8c6b-3d80e5049f62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(df_train['Summary_Length'], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af576M6LD_v5"
   },
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "G9bN11wwDc8M"
   },
   "outputs": [],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \" aint \": \"is not\", \"aren't\": \"are not\", \" arent \": \"are not\", \" cant \": \" cannot \", \"can't\": \"cannot\",\n",
    "                    \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldnt\": \"could not\", \"didn't\": \"did not\",\n",
    "                    \"didnt\": \"did not\", \" dint \": \"did not\", \"doesn't\": \"does not\", \"doesnt\": \"does not\", \"don't\": \"do not\", \" dont \": \" do not \", \"hadn't\": \"had not\",\n",
    "                    \"hadnt\": \"had not\", \"hasn't\": \"has not\", \"hasnt\": \"has not\", \"havent\": \"have not\", \"haven't\": \"have not\", \n",
    "                    \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \n",
    "                    \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                    \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n",
    "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                    \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "                    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\"shant\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n",
    "                    \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                    \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                    \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n",
    "                    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
    "                    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\":\n",
    "                    \"we have\", \"weren't\": \"were not\", \"werent\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                    \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                    \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
    "                    \"won't\": \"will not\", \"wont\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
    "                    \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "                    \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "                    \" ie \": \"that is\", \"i.e.\": \"that is\", \"Cc\": \"Carbon copy\", \" cc \": \" carbon copy \", \n",
    "                    \"TOR\": \"Terms of Reference\", 'eg.': 'example', 'MoU': 'Memorandum of Understanding', 'MoUs': 'Memorandums of Understanding',\n",
    "                    'MoM': 'Manufacturing Operations Management', \"It's\": \"It is\", \"m / h\": \"metres per hour\"\n",
    "                    # 'ime': 'ime', 'ites': 'ites', 'ile': 'ile', 'ide': 'ide', 'ime!': 'ime!', 'ise': 'ise', 'ike': 'ike', 'ife': 'ife',\n",
    "                    # 'ine.': 'ine.', 'ite': 'ite', 'ines': 'ines', 'iced': 'iced', 'ine': 'ine', 'ive ': 'ive ', 'ime ': 'ime', 'ile ': 'ile',\n",
    "                    # 'ide ': 'ide', 'ise ': 'ise ', 'ive-':'ive-', 'ives': 'ives', 'ike ': 'ike ', 'ife ': 'ife ', 'ite ': 'ite ', 'ine ': 'ine ',\n",
    "                    # 'idea': 'idea', 'imes': 'imes', 'ide.': 'ide.', 'ite,': 'ite,', 'ice ': 'ice ', 'iden': 'iden', 'ice,': 'ice,', 'ise,': 'ise,',\n",
    "                    # 'inen'\n",
    "                    }\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        if match.group(0) not in contractions.keys():\n",
    "            return match.group(0)\n",
    "        else:\n",
    "            return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling',\n",
    "                'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2',\n",
    "                'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What',\n",
    "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much',\n",
    "                'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does',\n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis',\n",
    "                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018',\n",
    "                'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp',\n",
    "                'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization',\n",
    "                'beklieve': 'believe', 'e-mail': 'email', 'p2p': 'peer to peer', 'up-to': 'upto', 'revenue-driven': 'revenue-driven',\n",
    "                'decision-makers': 'decision makers', 'Tvs': 'TVs', 'elswhere': 'elsewhere', 'traanslate': 'translate', 'oeder': 'order',\n",
    "                'up-to-date': 'up to date', 'win win': 'win-win', 'in-charge': 'in charge', 'invoincing': 'invoicing', 'discus': 'discuss',\n",
    "                'oraganize': 'organize', 'standsards': 'standards', 'Assuarance': 'Assurance','enterpreneural': 'enterpreneurial',\n",
    "                'Geo-politics': 'Geopolitics', 'estblish': 'establish', 'tought': 'taught', 'proffesionally': 'professionally',\n",
    "                'breifings': 'briefings', 'uodated': 'updated', 'hanlde': 'handle', 'tought': 'taught', 'instalment': 'installment',\n",
    "                'indepth': 'in depth', 'compamy': 'company', 'learge': 'large', 'aperson': 'a person', 'a pproach': 'approach',\n",
    "                'bein': 'being', ' eg ': ' eg. ', 'asses': 'assess', ' nee ': ' new ', 'organiszed': 'organized', 'inorder': 'in order', \n",
    "                'Incase': 'In case', 're-usable': 'reusable', 'eductae':'educate', 'begining': 'beginning', 'reserach': 'research',\n",
    "                'indentify': 'identify', 'belef': 'belief', 'persistant': 'persistent', 'intouch': 'in touch', 'negotaite': 'negotiate',\n",
    "                'relaevant': 'relevant', 'hnest': 'honest', 'up-todate': 'up to date', 'stafd': 'staff', 'tabke': 'table', \n",
    "                'aforeign': 'a foreign', 'organizagion': 'organisation', 'realible': 'reliable', 'Cordination': 'Coordination', \n",
    "                'seam,ess': 'seamless', 'neccesary': 'necessary', ' yo ': 'you', 'logistica': 'logistics', 'sanitzation': 'sanitization',\n",
    "                'organse': 'organise', 'aftter': 'after', 'traning': 'training', 'successfull': 'successful', 'consignmet': 'consignment',\n",
    "                'intrdue': 'introduce', 'prodcut': 'product', 'knwlegde': 'knowledge', 'roganizational': 'organisational', 'co-ordinate': 'coordinate',\n",
    "                'organizing': 'organising', 'diffrent': 'different', 'businnes': 'business', 'buisness': 'business', 'ecuses': 'excuses', 'financinal': 'financial',\n",
    "                'objecives': 'objectives', 'succesful': 'successful', 'fertilixzers': 'fertilizers', 'trianing': 'training',\n",
    "                'updatea': 'updated', 'someof': 'some of', 'boarder': 'border', 'deliveires': 'deliveries', 'exsisting': 'existing',\n",
    "                'elaviating': 'alleviating', 'excell': 'excel', 'goole': 'google', 'feedbackj': 'feedback', 'occasionaly': 'occassionally',\n",
    "                'parametres': 'parameters', 'sahre': 'share', 'aslo': 'also', 'emmediately': 'immediately', 'emmediate': 'immediate',\n",
    "                'prouect': 'product', 'quicke': 'quicker', 'termininal': 'terminal', 'aquick': 'a quick', 'conviencing': 'convincing',\n",
    "                'convience': 'convince', 'skillsi': 'skills', 'cordinated': 'coordinated', 'contriited': 'contributed', 'feilds': 'fields',\n",
    "                ' di ': 'did', 'incase': 'in case', 'bt': 'but', 'recollocet': 'reallocate', 'hoime': 'home', ' agri ': 'agriculture',\n",
    "                'studdies': 'studies', 'troble': 'trouble', 'govrmnet': 'government', 'referencde': 'referenced', 'approva': 'approval',\n",
    "                'Iwas': 'I was', 'startegic': 'strategic', 'suppprting': 'supporting', 'assosiation': 'association', 'thier': 'their', \n",
    "                ' inkind ': ' in kind ', 'discusss': 'discuss'}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        if match.group(0) not in mispellings.keys():\n",
    "            return match.group(0)\n",
    "        else:\n",
    "            return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "def replace_utf8_encodings(free_text):\n",
    "    ft = re.sub(r'â€™', \"'\", free_text)\n",
    "    ft = re.sub(r'â€“', \"-\", ft)\n",
    "    ft = re.sub(r'â€˜', \"'\", ft)\n",
    "    ft = re.sub(r'â€¦', \"…\", ft)\n",
    "    ft = re.sub(r'â€œ', '“', ft)\n",
    "    ft = re.sub(r'Â£', '£', ft)\n",
    "    ft = re.sub(r'â€¢', '-', ft)\n",
    "    return ft    \n",
    "\n",
    "# sc = SpellChecker()\n",
    "# def replace_other_misspells(text):\n",
    "#     tokens = wordpunct_tokenize(text)\n",
    "#     # Possibly prevent NEs from being judged as wrongly spelled\n",
    "#     needed_tokens = [token for token in tokens if not token[0].isupper() and token not in string.punctuation]\n",
    "#     print(needed_tokens)\n",
    "#     misspelled = sc.unknown(needed_tokens)\n",
    "#     print(misspelled)\n",
    "#     if misspelled != set():\n",
    "#         for token in misspelled:\n",
    "#             correct = sc.correction(token)\n",
    "#             print(correct)\n",
    "#             try:\n",
    "#                 text = re.sub(token, correct, text)\n",
    "#             except: pass\n",
    "#     return text\n",
    "\n",
    "def preprocess_text(free_text):\n",
    "    # remove non-word characters    \n",
    "    ft = free_text.strip()\n",
    "    ft = re.sub('\\x01', '', ft)\n",
    "    ft = re.sub('\\xa0', '', ft)\n",
    "    ft = replace_utf8_encodings(ft)\n",
    "    ft = re.sub(r'\\n{2}', '.', ft)\n",
    "    ft = re.sub('&rsquo;', \"'\", ft)\n",
    "    if bool(re.search(r'[@â€�™Âœ“ï§¬ž¢¶±ª–ƒÃ˜Ë„ðŸ˜ãƒ»†ðŒï˜]', ft)):\n",
    "        ft = re.sub(r'[@â€�™Âœ“ï§¬ž¢¶±ª–ƒÃ˜Ë„ðŸ˜ãƒ»†ðŒï˜]', '', ft)\n",
    "#     ft = re.sub(r'\\s\\.{2,6}(\\s|$)', ' ', ft)\n",
    "#     ft = re.sub(r\"([a-zA-Z])([\\.,/:;!?])\", r'\\1 \\2', ft)\n",
    "    ft = re.sub(r\"(['])(\\.)\", r\"\\1 \\2\", ft)\n",
    "    ft = re.sub(r\"(\\.)(['])\", r\"\\1 \\2\", ft)\n",
    "    ft = re.sub(r'([\"])(\\.)', r\"\\1 \\2\", ft)\n",
    "    ft = re.sub(r'(\\.)([\"])', r\"\\1 \\2\", ft)\n",
    "#     ft = re.sub(r'([\\.,/:;!?])([a-zA-Z])', r'\\1 \\2', ft)\n",
    "    ft = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', ft)\n",
    "    ft = re.sub(r'(\\w)(,)(\\w)', r'\\1 \\2 \\3', ft)\n",
    "    # get rid of 2 or more \n",
    "#     ft = re.sub(r'\\s\\.{2,}\\s', ' ', ft)\n",
    "    ft = re.sub(r'([a-zA-Z0-9#])(!)', r'\\1 \\2', ft)\n",
    "    ft = replace_contractions(ft)\n",
    "    ft = replace_typical_misspell(ft)\n",
    "    # ft = replace_other_misspells(ft)\n",
    "    if bool(re.search(r'\\d', ft)):\n",
    "        ft = re.sub(r'([0-9]+)(\\.)', r'\\1', ft)\n",
    "        ft = re.sub(r'([0-9]+)(\\))', r'\\1', ft)\n",
    "        # x = re.sub('$[0-9]+(\\.)', '\\1 \\2', ft)\n",
    "        # x = re.sub('$[0-9]+(\\))', '\\1 \\2', ft)\n",
    "#         ft = re.sub('[0-9]{5,}', '#####', ft)\n",
    "#         ft = re.sub('[0-9]{4}', '####', ft)\n",
    "#         ft = re.sub('[0-9]{3}', '###', ft)\n",
    "#         ft = re.sub('[0-9]{2}', '##', ft)\n",
    "    return ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4VUhu7ITqOx"
   },
   "source": [
    "#### Test the Text Preprocessing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "151MKL4uYwnI",
    "outputId": "34edc08f-5993-4a4e-9b13-f3740f9bd2a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Brief \\n  \\n San Francisco named top U.S. city \\n  \\n San Francisco has done it again. For the 17th straight year, the City by the Bay was named best U.S. city to visit in the Readers' Choice Awards from Conde Nast Traveler magazine. \\n  \\n Best cities, hotels, resorts, airlines and more are selected based on a survey of 25,000 readers. Results are revealed in the November issue. \\n  \\n San Francisco edged out Charleston, S.C., for the top spot among U.S. cities. Other top cities include Ubud, Bali, for Asia; Vancouver, Canada, for the Americas; and Florence, Italy, for Europe. \\n  \\n Four Seasons Tented Camp Golden Triangle in Chiang Rai, Thailand, was No. 1 on the Top 100 list of hotels, resorts and cruise lines. Kenwood Inn and Spa in Sonoma was the highest ranking California property at No. 36. \\n  \\n Other top award recipients included Celebrity for mega cruise line, Hertz for rental car, Virgin for North American airline and Singapore for global airline. \\n  \\n Airport updates \\n  \\n San Jose International Airport will receive almost $21 million from the U.S. Transportation Security Administration for a new state-of-the-art baggage screening system at the airport's new Terminal B. ... Harmony Pharmacy and Flu Ease will dispense flu shots through Dec. 13 to interested passengers at San Francisco International Airport. Travelers 18 and older can pay $35 to receive a shot at one of three locations in the airport. Details: www.flysfo.com. \\n  \\n Advertisement \\n  \\n U.S. roads renamed \\n  \\n Overseas Highway in the Florida Keys and four other U.S. roads have received recognition as All-American Roads. The 127-mile stretch of the Overseas Highway includes 42 bridges extending over the Gulf of Mexico, Atlantic Ocean and Florida Bay. \\n  \\n The other four new All-American Roads are Historic Route 66 in Arizona, Acadia All-American Road Trenton Extension in Maine, the Harriet Tubman Underground Railroad Byway in Maryland and Woodward Avenue Automotive Heritage Trail in Michigan. \\n  \\n Explore Irish gardens \\n  \\n Bancroft Gardens in Walnut Creek is offering a 10-day Tour of Irish Gardens for May. \\n  \\n The package, starting at $2,650 per person (based on double occupancy), includes ground transportation, hotel accommodations, breakfast, dinner, a boat trip to Garinish Island, a horse-drawn jaunting car ride in Killarney and admission to 13 castles and gardens. Airfare is $950 per person (taxes and fees not included). \\n  \\n For more information, call Mimi Knox at Cruise Adventures Unlimited, 925-935-7447. \\n  \\n — Ann Tatko-Peterson ||||| Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. Flowing in every day, these data are added to the Wayback Machine after an embargo period. |||||\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['document'].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvhf7rD3aGcd",
    "outputId": "73a62390-74a4-4a6e-b582-9ddeb62453f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Brief \n",
      "  \n",
      " San Francisco named top U.S. city \n",
      "  \n",
      " San Francisco has done it again. For the 17th straight year, the City by the Bay was named best U.S. city to visit in the Readers' Choice Awards from Conde Nast Traveler magazine. \n",
      "  \n",
      " Best cities, hotels, resorts, airlines and more are selected based on a survey of 25,000 readers. Results are revealed in the November issue. \n",
      "  \n",
      " San Francisco edged out Charleston, S.C., for the top spot among U.S. cities. Other top cities include Ubud, Bali, for Asia; Vancouver, Canada, for the Americas; and Florence, Italy, for Europe. \n",
      "  \n",
      " Four Seasons Tented Camp Golden Triangle in Chiang Rai, Thailand, was No. 1 on the Top 100 list of hotels, resorts and cruise lines. Kenwood Inn and Spa in Sonoma was the highest ranking California property at No. 36. \n",
      "  \n",
      " Other top award recipients included Celebrity for mega cruise line, Hertz for rental car, Virgin for North American airline and Singapore for global airline. \n",
      "  \n",
      " Airport updates \n",
      "  \n",
      " San Jose International Airport will receive almost $21 million from the U.S. Transportation Security Administration for a new state-of-the-art baggage screening system at the airport's new Terminal B. ... Harmony Pharmacy and Flu Ease will dispense flu shots through Dec. 13 to interested passengers at San Francisco International Airport. Travelers 18 and older can pay $35 to receive a shot at one of three locations in the airport. Details: www.flysfo.com. \n",
      "  \n",
      " Advertisement \n",
      "  \n",
      " U.S. roads renamed \n",
      "  \n",
      " Overseas Highway in the Florida Keys and four other U.S. roads have received recognition as All-American Roads. The 127-mile stretch of the Overseas Highway includes 42 bridges extending over the Gulf of Mexico, Atlantic Ocean and Florida Bay. \n",
      "  \n",
      " The other four new All-American Roads are Historic Route 66 in Arizona, Acadia All-American Road Trenton Extension in Maine, the Harriet Tubman Underground Railroad Byway in Maryland and Woodward Avenue Automotive Heritage Trail in Michigan. \n",
      "  \n",
      " Explore Irish gardens \n",
      "  \n",
      " Bancroft Gardens in Walnut Creek is offering a 10-day Tour of Irish Gardens for May. \n",
      "  \n",
      " The package, starting at $2,650 per person (based on double occupancy), includes ground transportation, hotel accommodations, breakfast, dinner, a boat trip to Garinish Island, a horse-drawn jaunting car ride in Killarney and admission to 13 castles and gardens. Airfare is $950 per person (taxes and fees not included). \n",
      "  \n",
      " For more information, call Mimi Knox at Cruise Adventures Unlimited, 925-935-7447. \n",
      "  \n",
      " — Ann Tatko-Peterson ||||| Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. Flowing in every day, these data are added to the Wayback Machine after an embargo period. |||||\n"
     ]
    }
   ],
   "source": [
    "print(df_train['document'].values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "8NeVXdgvcCzm",
    "outputId": "b5298080-a926-4a82-bf10-200b7a49242c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Brief \\n  \\n San Francisco named top U.S. city \\n  \\n San Francisco has done it again. For the 17 th straight year, the City by the Bay was named best U.S. city to visit in the Readers' Choice Awards from Conde Nast Traveler magazine. \\n  \\n Best cities, hotels, resorts, airlines and more are selected based on a survey of 25 , 000 readers. Results are revealed in the November issue. \\n  \\n San Francisco edged out Charleston, S.C., for the top spot among U.S. cities. Other top cities include Ubud, Bali, for Asia; Vancouver, Canada, for the Americas; and Florence, Italy, for Europe. \\n  \\n Four Seasons Tented Camp Golden Triangle in Chiang Rai, Thailand, was No. 1 on the Top 100 list of hotels, resorts and cruise lines. Kenwood Inn and Spa in Sonoma was the highest ranking California property at No. 36 \\n  \\n Other top award recipients included Celebrity for mega cruise line, Hertz for rental car, Virgin for North American airline and Singapore for global airline. \\n  \\n Airport updates \\n  \\n San Jose International Airport will receive almost $21 million from the U.S. Transportation Security Administration for a new state-of-the-art baggage screening system at the airport's new Terminal B. ... Harmony Pharmacy and Flu Ease will dispense flu shots through Dec. 13 to interested passengers at San Francisco International Airport. Travelers 18 and older can pay $35 to receive a shot at one of three locations in the airport. Details: www.flysfo.com. \\n  \\n Advertisement \\n  \\n U.S. roads renamed \\n  \\n Overseas Highway in the Florida Keys and four other U.S. roads have received recognition as All-American Roads. The 127-mile stretch of the Overseas Highway includes 42 bridges extending over the Gulf of Mexico, Atlantic Ocean and Florida Bay. \\n  \\n The other four new All-American Roads are Historic Route 66 in Arizona, Acadia All-American Road Trenton Extension in Maine, the Harriet Tubman Underground Railroad Byway in Maryland and Woodward Avenue Automotive Heritage Trail in Michigan. \\n  \\n Explore Irish gardens \\n  \\n Bancroft Gardens in Walnut Creek is offering a 10-day Tour of Irish Gardens for May. \\n  \\n The package, starting at $2 , 650 per person (based on double occupancy), includes ground transportation, hotel accommodations, breakfast, dinner, a boat trip to Garinish Island, a horse-drawn jaunting car ride in Killarney and admission to 13 castles and gardens. Airfare is $950 per person (taxes and fees not included). \\n  \\n For more information, call Mimi Knox at Cruise Adventures Unlimited, 925-935-7447 \\n  \\n — Ann Tatko-Peterson ||||| Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. Flowing in every day, these data are added to the Wayback Machine after an embargo period. |||||\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(df_train['document'].values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXMU1I4HTnor",
    "outputId": "80d05512-9860-43a1-fc96-47423043c0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Brief \n",
      "  \n",
      " San Francisco named top U.S. city \n",
      "  \n",
      " San Francisco has done it again. For the 17 th straight year, the City by the Bay was named best U.S. city to visit in the Readers' Choice Awards from Conde Nast Traveler magazine. \n",
      "  \n",
      " Best cities, hotels, resorts, airlines and more are selected based on a survey of 25 , 000 readers. Results are revealed in the November issue. \n",
      "  \n",
      " San Francisco edged out Charleston, S.C., for the top spot among U.S. cities. Other top cities include Ubud, Bali, for Asia; Vancouver, Canada, for the Americas; and Florence, Italy, for Europe. \n",
      "  \n",
      " Four Seasons Tented Camp Golden Triangle in Chiang Rai, Thailand, was No. 1 on the Top 100 list of hotels, resorts and cruise lines. Kenwood Inn and Spa in Sonoma was the highest ranking California property at No. 36 \n",
      "  \n",
      " Other top award recipients included Celebrity for mega cruise line, Hertz for rental car, Virgin for North American airline and Singapore for global airline. \n",
      "  \n",
      " Airport updates \n",
      "  \n",
      " San Jose International Airport will receive almost $21 million from the U.S. Transportation Security Administration for a new state-of-the-art baggage screening system at the airport's new Terminal B. ... Harmony Pharmacy and Flu Ease will dispense flu shots through Dec. 13 to interested passengers at San Francisco International Airport. Travelers 18 and older can pay $35 to receive a shot at one of three locations in the airport. Details: www.flysfo.com. \n",
      "  \n",
      " Advertisement \n",
      "  \n",
      " U.S. roads renamed \n",
      "  \n",
      " Overseas Highway in the Florida Keys and four other U.S. roads have received recognition as All-American Roads. The 127-mile stretch of the Overseas Highway includes 42 bridges extending over the Gulf of Mexico, Atlantic Ocean and Florida Bay. \n",
      "  \n",
      " The other four new All-American Roads are Historic Route 66 in Arizona, Acadia All-American Road Trenton Extension in Maine, the Harriet Tubman Underground Railroad Byway in Maryland and Woodward Avenue Automotive Heritage Trail in Michigan. \n",
      "  \n",
      " Explore Irish gardens \n",
      "  \n",
      " Bancroft Gardens in Walnut Creek is offering a 10-day Tour of Irish Gardens for May. \n",
      "  \n",
      " The package, starting at $2 , 650 per person (based on double occupancy), includes ground transportation, hotel accommodations, breakfast, dinner, a boat trip to Garinish Island, a horse-drawn jaunting car ride in Killarney and admission to 13 castles and gardens. Airfare is $950 per person (taxes and fees not included). \n",
      "  \n",
      " For more information, call Mimi Knox at Cruise Adventures Unlimited, 925-935-7447 \n",
      "  \n",
      " — Ann Tatko-Peterson ||||| Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. Flowing in every day, these data are added to the Wayback Machine after an embargo period. |||||\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_text(df_train['document'].values[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xy6n1f3cFWFe",
    "outputId": "3d57aa13-3982-42cf-c537-f4f5c99fa416"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 44972/44972 [16:13<00:00, 46.17it/s]\n",
      "100%|████████████████████████████████████| 44972/44972 [01:57<00:00, 384.06it/s]\n",
      "100%|███████████████████████████████████████| 5622/5622 [01:58<00:00, 47.34it/s]\n",
      "100%|██████████████████████████████████████| 5622/5622 [00:14<00:00, 386.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['preprocessed_articles'] = df_train['document'].progress_apply(preprocess_text)\n",
    "df_train['preprocessed_summaries'] = df_train['summary'].progress_apply(preprocess_text)\n",
    "df_val['preprocessed_articles'] = df_val['document'].progress_apply(preprocess_text)\n",
    "df_val['preprocessed_summaries'] = df_val['summary'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "kIUG85dn3VeB"
   },
   "outputs": [],
   "source": [
    "df_train['preprocessed_summaries'] = df_train['preprocessed_summaries'].apply(lambda x: '_START_ ' + x + ' _END_')\n",
    "df_val['preprocessed_summaries'] = df_val['preprocessed_summaries'].apply(lambda x: '_START_ ' + x + ' _END_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nopoDgDFIKNW"
   },
   "source": [
    "### Declare and Initialize separate Keras Tokenizers for Article and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZOP0lORa486"
   },
   "source": [
    "#### Text Tokenizer for Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "qWi2LrHZIJgV"
   },
   "outputs": [],
   "source": [
    "article_tk = Tokenizer(filters = '')\n",
    "article_tk.fit_on_texts(df_train['preprocessed_articles'].tolist() + df_val['preprocessed_articles'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKMLi1zLbVCw"
   },
   "source": [
    "#### Text Tokenizer for Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Cr6Q2ZQSbB7S"
   },
   "outputs": [],
   "source": [
    "summary_tk = Tokenizer(filters = '')\n",
    "summary_tk.fit_on_texts(df_train['preprocessed_summaries'].tolist() + df_val['preprocessed_summaries'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LON12Z-0GP6"
   },
   "source": [
    "### Extract GLoVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "BBXyAQhzzcFP"
   },
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "embedding_path = 'glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "jhMKM77h0vTS"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "# return word and its corresponding 300 dimensional vector as a dictionary\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4dgVK1i1Ii-",
    "outputId": "ef1dd726-7933-47a8-b00d-5250277361bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3364: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D numpy array of dimensions 840B x 300D using only the vector values of words \n",
    "all_embs = np.stack(embedding_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "I0bHRAQJ1L5-"
   },
   "outputs": [],
   "source": [
    "# Extract mean and standard deviation of vector values to be used for replacing missing values\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAU1vKq0gAuu"
   },
   "source": [
    "#### Generate Separate Embedding Matrices for Articles and Summaries to provide as Inputs to Encoder and Decoder respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhtsmMRagQ0M"
   },
   "source": [
    "##### Embeddings for Articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "HwRycv1s1Otg"
   },
   "outputs": [],
   "source": [
    "# Create vocabulary using tokenizer's assigned indices to words\n",
    "article_word_index = article_tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pM0Rak461TxI",
    "outputId": "2409fd38-7be5-4c98-fabd-02c39df799f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411217"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide the maximum number of words to be used from the vocabulary\n",
    "article_vocab_size = len(article_word_index) + 1\n",
    "article_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "sdAf2zjC1Zve"
   },
   "outputs": [],
   "source": [
    "# generate a 2D matrix that comprises of values from a normal random distribution generated using Mean and Standard Deviation of the vector values\n",
    "# obtained from a previous step.\n",
    "# We can also initialize the entire matrix with zero values\n",
    "# Matrix Dimensions = (Max Features + 1) words x 300 Dimensions\n",
    "article_embedding_matrix = np.random.normal(emb_mean, emb_std, (article_vocab_size, embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "BB5tsBJr1axz"
   },
   "outputs": [],
   "source": [
    "# Replace the row with index 'i' of the mebedding matrix with the vector of the word assigned value 'i' in the word index\n",
    "for word, i in article_word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        article_embedding_matrix[i] = embedding_vector\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhLP8qOk1udg",
    "outputId": "0c7ca2a0-b56e-4053-c9c4-d2c7d8e44976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411217, 300)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3IHs-Fygx0_"
   },
   "source": [
    "##### Embeddings for Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iWE2PQXFgx1A"
   },
   "outputs": [],
   "source": [
    "# Create vocabulary using tokenizer's assigned indices to words\n",
    "summary_word_index = summary_tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTE-nFQ8gx1B",
    "outputId": "1b2f9a5e-1ef1-4208-c86b-529befb33fb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372092"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide the maximum number of words to be used from the vocabulary\n",
    "summary_vocab_size = len(summary_word_index) + 1\n",
    "summary_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "k_cgXEyvgx1F"
   },
   "outputs": [],
   "source": [
    "# generate a 2D matrix that comprises of values from a normal random distribution generated using Mean and Standard Deviation of the vector values\n",
    "# obtained from a previous step.\n",
    "# We can also initialize the entire matrix with zero values\n",
    "# Matrix Dimensions = (Max Features + 1) words x 300 Dimensions\n",
    "summary_embedding_matrix = np.random.normal(emb_mean, emb_std, (summary_vocab_size, embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "6OhxQuX0gx1F"
   },
   "outputs": [],
   "source": [
    "# Replace the row with index 'i' of the mebedding matrix with the vector of the word assigned value 'i' in the word index\n",
    "for word, i in summary_word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        summary_embedding_matrix[i] = embedding_vector\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RDqiE3ngx1F",
    "outputId": "eb14ceb1-a752-4ff2-a031-c690408a0314"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372092, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8SM8tEmdtWA"
   },
   "source": [
    "### Prepare Data for Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHKnTo-udXoB"
   },
   "source": [
    "#### Declare Maximum Values for Article Length and Summary Length & Batch Size for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "nCj88fceMUXe"
   },
   "outputs": [],
   "source": [
    "maxlen_article = 4100\n",
    "maxlen_summary = 365\n",
    "latent_dim = 300\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO9GUiukdojV"
   },
   "source": [
    "#### Convert Text Data into Sequences of Fixed Length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51d4bzUNeIeA"
   },
   "source": [
    "##### ***Use Post Padding***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-buwDDmWewrk"
   },
   "source": [
    "###### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "6W0n-KrSXLlD"
   },
   "outputs": [],
   "source": [
    "train_article_sequences = article_tk.texts_to_sequences(df_train['preprocessed_articles'].tolist())\n",
    "train_summary_sequences = summary_tk.texts_to_sequences(df_train['preprocessed_summaries'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "eZaI01MRe0Ca"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(train_article_sequences, maxlen = maxlen_article, padding = 'post')\n",
    "y_train = pad_sequences(train_summary_sequences, maxlen = maxlen_summary, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQVZFfwuPexj",
    "outputId": "2e47f473-fbb1-4428-b736-fdb33a962778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44972, 4100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQsGsxjwPc0Z",
    "outputId": "488aef23-09d0-4450-b60c-725a5d5b9318"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44972, 365)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENC46eUyfVVE"
   },
   "source": [
    "###### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "9-ciFgdFfVVE"
   },
   "outputs": [],
   "source": [
    "validation_article_sequences = article_tk.texts_to_sequences(df_val['preprocessed_articles'].tolist())\n",
    "validation_summary_sequences = summary_tk.texts_to_sequences(df_val['preprocessed_summaries'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "uZmQqwL9fVVF"
   },
   "outputs": [],
   "source": [
    "X_val = pad_sequences(validation_article_sequences, maxlen = maxlen_article, padding = 'post')\n",
    "y_val = pad_sequences(validation_summary_sequences, maxlen = maxlen_summary, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kOE1jEJPhAc",
    "outputId": "e1cbfa94-7547-44d8-d11c-ea6ddfc06618"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5622, 4100)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7omyl9L-PYu7",
    "outputId": "7be9e62a-57b8-4192-d4d3-dd45746410c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5622, 365)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9Atj-1qIsxK"
   },
   "source": [
    "### Check Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Yp7ilpRIvqo",
    "outputId": "2354d71b-ec7b-475d-c7fa-214c01ab7377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYL6tAfDIp19",
    "outputId": "dc3eb259-2722-49a4-a419-a30eed21fdd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvljY-UzIygs",
    "outputId": "bab9785c-04bb-4bab-de84-9a4fc3e85101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPJbUJn2I1ST",
    "outputId": "c5560a39-6636-4873-8033-bf72aab541cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DevnaAvZjrjy"
   },
   "source": [
    "### Generate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03JTpF3uRgtm"
   },
   "source": [
    "#### Custom Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "dKee0ck0RgOs"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Poi279twlLRw"
   },
   "source": [
    "##### ***Note: GLoVe Embeddings are pretrained, hence the trainable parameter is set to false***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "fUZd8x4okdoB"
   },
   "outputs": [],
   "source": [
    "# Encoder \n",
    "encoder_inputs = Input(shape = (maxlen_article,))\n",
    "enc_emb = Embedding(article_vocab_size, embed_size, input_length = maxlen_article, weights = [article_embedding_matrix], trainable = False)(encoder_inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "18hvwkkufSm9"
   },
   "outputs": [],
   "source": [
    "# LSTM 1 \n",
    "encoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True) \n",
    "encoder_output1, state_h, state_c = encoder_lstm(enc_emb) \n",
    "\n",
    "# LSTM 2 \n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences = True, return_state = True) \n",
    "encoder_output2, state_h1, state_c1 = encoder_lstm1(encoder_output1) \n",
    "\n",
    "# LSTM 3 \n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences = True, return_state = True) \n",
    "encoder_outputs, state_h2, state_c2 = encoder_lstm2(encoder_output2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "d5UfxYxkkhx_"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder. \n",
    "decoder_inputs = Input(shape = (None,))\n",
    "dec_emb_layer = Embedding(summary_vocab_size, embed_size, input_length = maxlen_summary, weights = [summary_embedding_matrix], trainable = False ) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "caEFg8i1knOZ"
   },
   "outputs": [],
   "source": [
    "# Initialize a decoder LSTM using final encoder LSTM's output states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True) \n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state = [state_h2, state_c2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "-OMQK2EvltU9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/W_a:0' shape=(300, 300) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/W_a:0' shape=(300, 300) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/V_a:0' shape=(300, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/V_a:0' shape=(300, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/W_a:0' shape=(300, 300) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/W_a:0' shape=(300, 300) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/V_a:0' shape=(300, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_layer/V_a:0' shape=(300, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4371\u001b[0m     \u001b[0;31m# tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m     input_ta = tuple(\n\u001b[0m\u001b[1;32m   4373\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4372\u001b[0m     input_ta = tuple(\n\u001b[0;32m-> 4373\u001b[0;31m         tensor_array_ops.TensorArray(\n\u001b[0m\u001b[1;32m   4374\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, name)\u001b[0m\n\u001b[1;32m   1067\u001b[0m       \u001b[0mimplementation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GraphTensorArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m     self._implementation = implementation(\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KerasTensor' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_b/8vsjj87100j536bwyk7_2s900000gn/T/ipykernel_84870/517561105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Attention Layer - Use BahdanauAttention for seq2seq tasks as standard Attention Layer raises a concatenation error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mattention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'attention_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mattention_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1056\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1057\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_b/8vsjj87100j536bwyk7_2s900000gn/T/ipykernel_84870/3043938349.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, verbose)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;34m\"\"\" Computing energy outputs \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# e_outputs => (batch_size, de_seq_len, en_seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         last_out, e_outputs, _ = K.rnn(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0menergy_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_out_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfake_state_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         )\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, args, kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GLOBAL_DISPATCHERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         for x in tf.nest.flatten([args, kwargs])):\n\u001b[0;32m-> 1473\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4535\u001b[0;31m       final_outputs = control_flow_ops.while_loop(\n\u001b[0m\u001b[1;32m   4536\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4537\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2727\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m   2728\u001b[0m       not executing_eagerly):\n\u001b[0;32m-> 2729\u001b[0;31m     return while_v2.while_loop(\n\u001b[0m\u001b[1;32m   2730\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloop_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations_arg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     body_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mbody_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mwrapped_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0;31m# `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;31m# and packs it into the structure of `orig_loop_vars`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4529\u001b[0m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4530\u001b[0;31m         output_ta_t = tuple(\n\u001b[0m\u001b[1;32m   4531\u001b[0m             ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))\n\u001b[1;32m   4532\u001b[0m         \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_new_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4529\u001b[0m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4530\u001b[0m         output_ta_t = tuple(\n\u001b[0;32m-> 4531\u001b[0;31m             ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))\n\u001b[0m\u001b[1;32m   4532\u001b[0m         \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_new_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m\"\"\"Decorates the input function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001b[0m\u001b[1;32m    248\u001b[0m                                      \u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                                      error_in_function=error_in_function)\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, index, value, name)\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mspecified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m-> 1156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, index, value, name)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TensorArrayV2Write\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m       \u001b[0;31m# TODO(b/129870929): Fix after all callers provide proper init dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m       value = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    535\u001b[0m           value, preferred_dtype=self._dtype, name=\"value\")\n\u001b[1;32m    536\u001b[0m       \u001b[0m_check_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                          as_ref=False):\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    286\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 288\u001b[0;31m       tensor_util.make_tensor_proto(\n\u001b[0m\u001b[1;32m    289\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m           allow_broadcast=allow_broadcast))\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_is_array_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;31m# We first convert value to a numpy array or scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ml_env/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;34m'This error may indicate that you\\'re trying to pass a symbolic value '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model."
     ]
    }
   ],
   "source": [
    "# Attention Layer - Use BahdanauAttention for seq2seq tasks as standard Attention Layer raises a concatenation error \n",
    "attention_layer = AttentionLayer(name = 'attention_layer')\n",
    "attention_out, attention_states = attention_layer([encoder_outputs, decoder_outputs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "0MCr7I5qnc3B"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attention_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_b/8vsjj87100j536bwyk7_2s900000gn/T/ipykernel_84870/2177109807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Concat attention output and decoder LSTM output columnwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder_concat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'attention_out' is not defined"
     ]
    }
   ],
   "source": [
    "# Concat attention output and decoder LSTM output columnwise\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "lYC6HLV5n_wG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_concat_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_b/8vsjj87100j536bwyk7_2s900000gn/T/ipykernel_84870/1558552477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Output Layer - Dense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_concat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_concat_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Output Layer - Dense\n",
    "decoder_dense = TimeDistributed(Dense(summary_vocab_size, activation = 'softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsOsdnR0oWAI",
    "outputId": "3bb583c1-0e5f-484d-b6bf-40896751513c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4100)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 4100, 300)    423365100   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 4100, 300),  721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 4100, 300),  721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    111627600   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 4100, 300),  721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "==================================================================================================\n",
      "Total params: 537,877,500\n",
      "Trainable params: 2,884,800\n",
      "Non-trainable params: 534,992,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define & Compile the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4UaGKYpr_5n"
   },
   "source": [
    "#### Define an EarlyStopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "pZaNXqQdsHUX"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrCECAzUdk1F"
   },
   "source": [
    "#### Verify Input Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WXlA6mCdnxY",
    "outputId": "1b8c67f3-4e4d-4f21-96fb-b86a8630f0c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 199)"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfipZCEKhYwA",
    "outputId": "2b4ef51d-d8af-42c0-b78e-ae98c0af9d6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 199, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aHkkmcXWUTN",
    "outputId": "4a8a4047-7488-490b-e98c-a12d27f804dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 199)"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkTbpYDnV5uS",
    "outputId": "6c7c1652-153b-4be6-d68e-10c0eec634a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 199, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd_hTP7psMkT"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "DRbYxCFjqFNR",
    "outputId": "e801b9cd-f3b9-49ed-a6b0-f5343ccd0fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-55ef19daaf5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[25472,24996] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_1/time_distributed/dense/Softmax (defined at <ipython-input-83-98f17e29f83d>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_12398]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:], epochs = 10, callbacks=[es], batch_size = batch_size, validation_data = ([X_val, y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qGm-8HJs4YR"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train') \n",
    "plt.plot(history.history['val_loss'], label='test') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGJJdzzKC8yZ"
   },
   "source": [
    "### Build vocabulary to convert index to word for the target and source vocabulary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcVAPIDgDKI5"
   },
   "outputs": [],
   "source": [
    "reverse_summary_word_index = summary_tk.index_word\n",
    "reverse_article_word_index = article_tk.index_word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7K80fvhu3aR"
   },
   "source": [
    "### Set up Inference Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNmxxSI-tX7J"
   },
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = [encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dk-pEB5yvCGA"
   },
   "outputs": [],
   "source": [
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(embed_size,))\n",
    "decoder_state_input_c = Input(shape=(embed_size,))\n",
    "decoder_hidden_state_input = Input(shape=(maxlen_article, embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7t5rOkJ8vFDa"
   },
   "outputs": [],
   "source": [
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acDF8wOvxwGx"
   },
   "outputs": [],
   "source": [
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = [decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5HL1Ar1x5q6"
   },
   "outputs": [],
   "source": [
    "#attention inference\n",
    "attention_out_inference = attention_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inference_concat = Concatenate(axis=-1, name = 'concat')([decoder_outputs2, attention_out_inference], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbJi0UA5yGiq"
   },
   "outputs": [],
   "source": [
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inference_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8pnsbtHyKWk"
   },
   "outputs": [],
   "source": [
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVaYlnx0yiU_"
   },
   "source": [
    "### Define a function to implement the Inference Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9-0z_oqynTw"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = summary_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_summary_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token != 'end'):\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFpctn2cyvHA"
   },
   "source": [
    "### Define a function to convert an Integer Sequence into a Word Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wqhkwo8Lyp5Z"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "      if((i != 0 and i != summary_word_index['start']) and i != summary_word_index['end']):\n",
    "        newString += reverse_summary_word_index[i] + ' '\n",
    "    return newString\n",
    "\n",
    "def seq2article(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "      if(i != 0):\n",
    "        newString += reverse_article_word_index[i] + ' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Up2yghJy-zq"
   },
   "source": [
    "### Obtain Summaries for the Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "Ju2sFvOUzFHr",
    "outputId": "a0f44187-e754-4533-ce91-3b8ffbd3fcba"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2b88068e190a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Article: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen_article\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-12fc67024b16>\u001b[0m in \u001b[0;36mseq2article\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnewString\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreverse_article_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reverse_article_word_index' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_val)):\n",
    "  print(\"Article: {}\".format(seq2article(X_val[i])))\n",
    "  print(\"Original summary: {}\".format(seq2summary(y_val[i])))\n",
    "  print(\"Predicted summary: {}\".format(decode_sequence(X_val[i].reshape(1, maxlen_article))))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXSeLQGpz4CX"
   },
   "source": [
    "### Test on an Extraneous Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "mJMO57N_z755",
    "outputId": "b64f2400-8e46-4444-86ee-d1c928b772ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"While erratic investor behaviour is well-known and documented when markets nosedive, it&rsquo;s not much different when the opposite happens.\\n\\nWhen markets trade at record highs, rational and logic take a backseat, and to make quick gains, investors end up committing certain mistakes they rue later. So, what are the things you should avoid in such a scenario? Let&rsquo;s find out.\\n\\nAvoid Investing in Bulk\\n\\nJumping onto the bull bandwagon, retail investors often end up investing in bulk when markets are trading at a peak. This must be avoided at all costs. Instead, they should invest in a staggered manner, diversifying their investments across asset classes.\\n\\nIf bulk investments are to be made, balanced advantage funds can prove to be a good bet as they dynamically adjust the equity and debt component as per prevailing market valuations. These funds lower equity exposure during market highs to prevent losses and vice versa.\\n\\nIn a bid to earn profits in the shortest possible time, investors tend to time the market. Instead, they should focus on remaining committed to their investment for the long haul for meaningful gains.\\n\\nDon&rsquo;t Cash Out from Quality Stocks\\n\\nDuring a market surge, valuation of high-quality stocks may seem overstretched. A common mistake committed in such a scenario is to sell them and buy stocks trading at lower valuations.\\n\\nThe move can prove to be detrimental in the long run. Also, one shouldn&rsquo;t buy low valuation stocks of the same industry by selling high-valuation ones. Fundamentally sound stocks will always add to your wealth in the long term and provide superior risk-adjusted returns.\\n\\nIt&rsquo;s prudent to stay with winners as the fundamentals of low valuation stocks may not support fresh investments into them.\\n\\nChanging Risk Appetite\\n\\nWhen markets are in a state of euphoria, suddenly investors tend to enhance their risk profile. Even a conservative investor becomes aggressive.\\n\\nHowever, it's important to understand that a change in risk profile doesn't materially change their risk appetite. A conservative investor, more often than not, will get nervy even at the slightest market swings.\\n\\nAny act conducted in such a scenario could off-balance one&rsquo;s asset allocation, putting financial plans in jeopardy. It's advisable to keep emotions under check and one must stick to his original risk appetite.\\n\\nThe Final Word\\n\\nMarkets are overheated now, and therefore, it&rsquo;s vital to exercise caution. Picking up the right stock at a fair price should be the focus, instead of buying stocks with lower valuations with no change in a company's fundamentals.\\n\\nGreed to make quick bucks should be tamed, and the emphasis should be on looking at the bigger picture encompassing your financial goals and risk appetite, among others. Avoid relying on emotions and getting carried away in the rally.\\n\\nHappy investing!\""
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = open('business_article.txt').read()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "nmKUhiFc23F6",
    "outputId": "57fa888f-9d6a-4681-966a-03217d80ed64"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"While erratic investor behaviour is well-known and documented when markets nosedive , it is not much different when the opposite happens When markets trade at record highs , rational and logic take a backseat , and to make quick gains , investors end up committing certain mistakes they rue later . So , what are the things you should avoid in such a scenario ? Let's find out Avoid Investing in Bulk . Jumping onto the bull bandwagon , retail investors often end up investing in bulk when markets are trading at a peak . This must be avoided at all costs . Instead , they should invest in a staggered manner , diversifying their investments across asset classess If bulk investments are to be made , balanced advantage funds can prove to be a good bet as they dynamically adjust the equity and debut component as per prevailing market valuations . These funds lower equity exposure during market highs to prevent losses and vice versa In a bid to earn profits in the shortest possible time , investors tend to time the market . Instead , they should focus on remaining committed to their investment for the long haul for meaningful gains Don't Cash Out from Quality Stocks . During a market surge , valuation of high-quality stocks may seem overstretched . A common mistake committed in such a scenario is to sell them and buy stocks trading at lower valuations The move can prove to be detrimental in the long run . Also , one should not buy low valuation stocks of the same industry by selling high-valuation ones . Fundamentally sound stocks will always add to your wealth in the long term and provide superior risk-adjusted returns It is prudent to stay with winners as the fundamentals of low valuation stocks may not support fresh investments into them Changing Risk Appetite . When markets are in a state of euphoria , suddenly investors tend to enhance their risk profile . Even a conservative investor becomes aggressive However , it is important to understand that a change in risk profile does not materially change their risk appetite . A conservative investor , more often than not , will get nervy even at the slightest market swings Any act conducted in such a scenario could off-balance one's asset allocation , putting financial plans in jeopardy . It is advisable to keep emotions under check and one must stick to his original risk appetite The Final Word . Markets are overheated now , and therefore , it is vital to exercise caution . Picking up the right stock at a fair price should be the focus , instead of buying stocks with lower valuations with no change in a company's fundamentals Greed to make quick bucks should be tamed , and the emphasis should be on looking at the bigger picture encompassing your financial goals and risk appetite , among others . Avoid relying on emotions and getting carried away in the rally Happy investing !\""
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = preprocess_text(content)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23wFhm-A3QZN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJsiJIh584L95P9Veg+UUb",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BBC News Text Summarization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
