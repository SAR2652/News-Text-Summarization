{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWPgHLPSRqYM",
        "outputId": "b34df135-7dd7-452f-a2a2-1eadadbe0fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5xW2dVmQzBV",
        "outputId": "bcd90b57-012a-4e57-b59e-87bc9b3b05a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1doFTTNNYPcd",
        "outputId": "00cdaaad-b8c8-4ed3-b4c4-afca910cfb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 13.8 MB/s \n",
            "\u001b[?25hCollecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow_datasets) (3.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.54.0)\n",
            "Installing collected packages: tensorflow-addons, pickle5\n",
            "Successfully installed pickle5-0.0.12 tensorflow-addons-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm tensorflow_datasets tensorflow_addons pickle5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j4atwxEtZGtW"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pickle5 as pickle\n",
        "import pandas as pd\n",
        "tqdm.pandas()\n",
        "import os, string, re, json, ast\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import wordpunct_tokenize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Embedding, Concatenate, TimeDistributed, RNN, LSTMCell, AdditiveAttention, GRU, LSTM\n",
        "from tensorflow.keras.backend import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Loss, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4-w8-pSCvPoJ"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/text_summarizer_models/no_glove/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "flPX0MC6azok"
      },
      "outputs": [],
      "source": [
        "tokenizer = pickle.load(open(filepath + 'tokenizer.pickle', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L-Mu0QjX11xM"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_features = vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIt5zu3TVVga",
        "outputId": "5298fbcc-b59f-42e6-c001-a172d0473ad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "197747"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_e6OMGNjCELA"
      },
      "outputs": [],
      "source": [
        "# Create vocabulary using tokenizer's assigned indices to words\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OzDlpw5HCcj3"
      },
      "outputs": [],
      "source": [
        "embed_size = 192\n",
        "maxlen_article = 550\n",
        "maxlen_summary = 50\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2uU8QkK_CkAR"
      },
      "outputs": [],
      "source": [
        "X_train = pickle.load(open(filepath + 'X_train.pickle', 'rb'))\n",
        "y_train = pickle.load(open(filepath + 'y_train.pickle', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6vi34upALqo_"
      },
      "outputs": [],
      "source": [
        "X_val = pickle.load(open(filepath + 'X_val.pickle', 'rb'))\n",
        "y_val = pickle.load(open(filepath + 'y_val.pickle', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFzrAuTLCp0F",
        "outputId": "48a9cf93-984e-436e-f377-1a6c75a6c0c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79519, 550)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViLbgfVEMHbL",
        "outputId": "d6f9b622-5b68-4431-bb6e-639c8730a79c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8836, 550)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF3HLn4fhZlh"
      },
      "source": [
        "## Text Summarizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MF_wQB9XAq-T"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = Embedding(self.input_vocab_size, embedding_dim, embeddings_initializer = 'glorot_normal')\n",
        "\n",
        "        # The GRU RNN layer processes those vectors sequentially.\n",
        "\n",
        "        self.lstm1 = LSTM(128, return_sequences=True, \n",
        "                     return_state=True)\n",
        "\n",
        "        # self.lstm2 = LSTM(128, return_sequences=True,\n",
        "        #              return_state=True)\n",
        "    \n",
        "        # self.lstm3 = LSTM(128, return_sequences=True,\n",
        "        #              return_state=True)\n",
        "\n",
        "    def call(self, tokens, state=None):\n",
        "    \n",
        "        # 2. The embedding layer looks up the embedding for each token.\n",
        "        vectors = self.embedding(tokens)\n",
        "\n",
        "        # 3. The GRU processes the embedding sequence.\n",
        "        #    output shape: (batch, s, enc_units)\n",
        "        #    state shape: (batch, enc_units)\n",
        "        output_1, state_h1, state_c1  = self.lstm1(vectors)\n",
        "        # output_2, state_h2, state_c2 = self.lstm2(output_1)\n",
        "        # output_3, state_h3, state_c3 = self.lstm3(output_2)\n",
        "        # 4. Returns the new sequence and its state.\n",
        "        # return output_3, state_h3\n",
        "        # return output_2, state_h2\n",
        "        return output_1, state_h1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H3TNTnFm2ODS"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BJf5ZZ74gruU"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VxTgV-jYA3TJ"
      },
      "outputs": [],
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # For Step 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = Embedding(self.output_vocab_size, embedding_dim, embeddings_initializer = 'glorot_normal')\n",
        "\n",
        "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # For step 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "        self.Wc = Dense(dec_units, activation=tf.keras.activations.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "        # For step 5. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.fc = Dense(self.output_vocab_size)\n",
        "    \n",
        "    def call(self, inputs: DecoderInput, state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "\n",
        "        # Step 1. Lookup the embeddings\n",
        "        vectors = self.embedding(inputs.new_tokens)\n",
        "    \n",
        "        # Step 2. Process one step with the RNN\n",
        "        rnn_output, state, carry_state = self.lstm(vectors)\n",
        "\n",
        "        # Step 3. Use the RNN output as the query for the attention over the\n",
        "        # encoder output.\n",
        "        context_vector, attention_weights = self.attention(query = rnn_output, value = inputs.enc_output, mask = inputs.mask)\n",
        "\n",
        "        # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "        #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "        context_and_rnn_output = tf.concat([context_vector, rnn_output], axis = -1)\n",
        "\n",
        "        # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "        attention_vector = self.Wc(context_and_rnn_output)\n",
        "        \n",
        "        # Step 5. Generate logit predictions:\n",
        "        logits = self.fc(attention_vector)\n",
        "\n",
        "        return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7D0DJW5Lts07"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(Loss):\n",
        "    def __init__(self):\n",
        "        self.name = 'masked_loss'\n",
        "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        # Calculate the loss for each item in the batch.\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "    \n",
        "        # Mask off the losses on padding.\n",
        "        mask = tf.cast(y_true != 0, tf.float32)\n",
        "        loss *= mask\n",
        "\n",
        "        # Return the total.\n",
        "        return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X-znrarH29Kd"
      },
      "outputs": [],
      "source": [
        "class TextSummarizerModel(Model):\n",
        "    def __init__(self, use_tf_function=True):\n",
        "        super(TextSummarizerModel, self).__init__()\n",
        "        self.encoder = Encoder(vocab_size, embed_size)\n",
        "        self.decoder = Decoder(vocab_size, embed_size, 128)\n",
        "        self.use_tf_function = use_tf_function\n",
        "\n",
        "    def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "        input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "        # Run the decoder one step.\n",
        "        decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "        # print('Entered Decoder')\n",
        "        dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "        # print('Exit Decoder')\n",
        "        # `self.loss` returns the total for non-padded tokens\n",
        "        y = target_token\n",
        "        y_pred = dec_result.logits\n",
        "        step_loss = self.loss(y, y_pred)\n",
        "        # print('Exit Loop Decoder')\n",
        "        return step_loss, dec_state\n",
        "\n",
        "    def get_masks(self, input_tokens, target_tokens):\n",
        "        return (input_tokens != 0), (target_tokens != 0)\n",
        "\n",
        "    def test_step(self, inputs):\n",
        "        max_target_length = maxlen_summary\n",
        "        X_eval, y_eval = inputs\n",
        "        input_mask, target_mask = self.get_masks(X_eval, y_eval)\n",
        "        enc_output, enc_state = self.encoder(X_eval)\n",
        "        dec_state = enc_state\n",
        "        loss = tf.constant(0.0)\n",
        "        for t in range(max_target_length - 1):\n",
        "            new_tokens = y_eval[:, t:t+2]\n",
        "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "            loss = loss + step_loss\n",
        "        \n",
        "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "        return {'average_loss': average_loss}\n",
        "\n",
        "    def _train_step(self, input_tokens, target_tokens):\n",
        "        max_target_length = maxlen_summary\n",
        "\n",
        "        steps_per_epoch = X_train.shape[0] // batch_size\n",
        "\n",
        "        for i in tf.range(steps_per_epoch):\n",
        "\n",
        "            batch_inputs = input_tokens[i * batch_size: (i + 1) * batch_size, :]\n",
        "            batch_outputs = target_tokens[i * batch_size: (i + 1) * batch_size, :]\n",
        "\n",
        "            input_mask, target_mask = self.get_masks(batch_inputs, batch_outputs)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Encode the input\n",
        "                enc_output, enc_state = self.encoder(batch_inputs)\n",
        "\n",
        "                # Initialize the decoder's state to the encoder's final state.\n",
        "                # This only works if the encoder and decoder have the same number of\n",
        "                # units.\n",
        "                dec_state = enc_state\n",
        "                loss = tf.constant(0.0)\n",
        "\n",
        "                for t in tf.range(max_target_length - 1):\n",
        "                    # Pass in two tokens from the target sequence:\n",
        "                    # 1. The current input to the decoder.\n",
        "                    # 2. The target for the decoder's next prediction.\n",
        "                    new_tokens = batch_outputs[:, t:t+2]\n",
        "                    step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "                    loss = loss + step_loss\n",
        "\n",
        "                # Average the loss over all non padding tokens.\n",
        "                average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "            # Apply an optimization step\n",
        "            variables = self.trainable_variables\n",
        "            gradients = tape.gradient(average_loss, variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "            # Return a dict mapping metric names to current value\n",
        "            # print('Batch {}: Loss = {}'.format(i, average_loss))\n",
        "            # print('Time Taken for batch: {}s'.format(time.time() - start_time))\n",
        "            return {'batch_loss': average_loss}\n",
        "\n",
        "    @tf.function\n",
        "    def _tf_train_step(self, input_tokens, output_tokens):\n",
        "        # print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "        return self._train_step(input_tokens, output_tokens)\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        input_tokens, output_tokens = inputs\n",
        "        if self.use_tf_function:\n",
        "            return self._tf_train_step(input_tokens, output_tokens)\n",
        "        else:\n",
        "            return self._train_step(input_tokens, output_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "u2zSevmMxUKj"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.logs = []\n",
        "\n",
        "    def on_train_batch_end(self, n, logs):\n",
        "        self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_path = 'optimizer_weights_03-02-2022_17:_34:_15_12.npy'\n",
        "optimizer_weights_path = filepath + opt_path"
      ],
      "metadata": {
        "id": "gmd23l42v9OM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_weights = np.load(optimizer_weights_path, allow_pickle = True)"
      ],
      "metadata": {
        "id": "8Ry6-uLh4NNu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cgA17jgWxEKn"
      },
      "outputs": [],
      "source": [
        "model = TextSummarizerModel()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "iyrQIYJLvNgr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizerSaver(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        weights = optimizer.get_weights()\n",
        "        optimizer_path = filepath + 'optimizer_weights_' + dt_string + '_{}.npy'.format(epoch)\n",
        "        np.save(optimizer_path, optimizer.get_weights())\n",
        "\n",
        "op_saver = OptimizerSaver()"
      ],
      "metadata": {
        "id": "B-yASsT1wW48"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the loss and optimizer\n",
        "model.compile(optimizer = optimizer, loss = MaskedLoss())"
      ],
      "metadata": {
        "id": "yJMQ0zAf33yH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = 'retrained_model_checkpoint_weights_03-02-2022_17:_34:_15_13.h5'"
      ],
      "metadata": {
        "id": "3yLse-583On1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "WtVd2ujq3a7h",
        "outputId": "46a610d9-8e8b-49a5-de0e-dd2de4ba0dcf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   3/2485 [..............................] - ETA: 7:54:06 - batch_loss: 11.9235"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d768f88d541e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.set_weights(optimizer_weights)"
      ],
      "metadata": {
        "id": "OmW1gDKt4ICg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = optimizer, loss = MaskedLoss())"
      ],
      "metadata": {
        "id": "Ct8V2Yu3Jvmp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.built = True"
      ],
      "metadata": {
        "id": "yZAMEsi23taE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filepath + weights_path)"
      ],
      "metadata": {
        "id": "i9ks_Q0s3KEh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y_%H:_%M:_%S\")"
      ],
      "metadata": {
        "id": "FMdEkE5bUWan"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V4NnoGS_mlt",
        "outputId": "6b3f18b5-49aa-4bed-e79f-59936fa6d9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "ckpt_filepath = filepath + 'retrained_model_checkpoint_weights_'+ dt_string +'_{epoch:02d}.h5'\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "\tckpt_filepath,\n",
        "\tperiod=1,\n",
        "\tmonitor=\"batch_loss\",\n",
        "\tverbose=0,\n",
        "\tsave_best_only=False,\n",
        "\tsave_weights_only=True,\n",
        "\tmode=\"auto\",\n",
        "\tsave_freq=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx8-h6tayIv1"
      },
      "source": [
        "### Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3Xla7hMDVnPb"
      },
      "outputs": [],
      "source": [
        "class Summarizer(tf.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.output_token_string_from_index = (tf.keras.layers.StringLookup(\n",
        "            vocabulary = list(word_index.keys()),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "        # The output should never generate padding, unknown, or start.\n",
        "        index_from_string = tf.keras.layers.StringLookup(vocabulary = list(word_index.keys()), mask_token='')\n",
        "        token_mask_ids = index_from_string(['', '<s>', '</s>']).numpy()\n",
        "        token_mask = np.zeros([vocab_size], dtype=np.bool)\n",
        "        token_mask[np.array(token_mask_ids)] = True\n",
        "        self.token_mask = token_mask\n",
        "        self.start_token = index_from_string(tf.constant('<s>'))\n",
        "        self.end_token = index_from_string(tf.constant('</s>'))\n",
        "    \n",
        "    def tokens_to_text(self, result_tokens):\n",
        "        result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "        \n",
        "        result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "\n",
        "        result_text = tf.strings.strip(result_text)\n",
        "        return result_text\n",
        "\n",
        "    def sample(self, logits, temperature):\n",
        "        token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  \n",
        "        # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "        logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "        if temperature == 0.0:\n",
        "            new_tokens = tf.argmax(logits, axis=-1)\n",
        "        else: \n",
        "            logits = tf.squeeze(logits, axis=1)\n",
        "        \n",
        "        new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "        return new_tokens\n",
        "\n",
        "    def abstractive_summarize(self, input_tokens, *, max_length=maxlen_article, return_attention=True, temperature=1.0):\n",
        "        batch_size = tf.shape(input_tokens)[0]\n",
        "        enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "        result_tokens = []\n",
        "        attention = []\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "            dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "            attention.append(dec_result.attention_weights)\n",
        "\n",
        "            new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "            # If a sequence produces an `end_token`, set it `done`\n",
        "            done = done | (new_tokens == self.end_token)\n",
        "            # Once a sequence is done it only produces 0-padding.\n",
        "            new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "            # Collect the generated tokens\n",
        "            result_tokens.append(new_tokens)\n",
        "\n",
        "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "                break\n",
        "\n",
        "        # Convert the list of generates token ids to a list of strings.\n",
        "        result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "        result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "        if return_attention:\n",
        "            attention_stack = tf.concat(attention, axis=1)\n",
        "            return {'text': result_text, 'attention': attention_stack}\n",
        "        else:\n",
        "            return {'text': result_text}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(dtype=tf.int32, shape=[None, maxlen_article])])\n",
        "    def tf_summarize(self, input_tokens):\n",
        "        return self.abstractive_summarize(input_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SSlPvCpBW-q6"
      },
      "outputs": [],
      "source": [
        "summarizer = Summarizer(encoder = model.encoder, decoder = model.decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "AzeHqc2wZ7as",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4349b180-65b4-48fd-abc1-fe6d692e5d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: summarizer/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: summarizer/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(summarizer, 'summarizer',\n",
        "                    signatures={'serving_default': summarizer.tf_summarize})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcbO733GyA_K"
      },
      "outputs": [],
      "source": [
        "summarizer.tf_summarize(X_val[:2, :])['text']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv summarizer /content/drive/MyDrive/text_summarizer_models/"
      ],
      "metadata": {
        "id": "rcaE8VogkyR_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bfc9cjKiKjNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Model Test (No GLoVe + Bahdanau only and No Preprocessing).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}