{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWPgHLPSRqYM",
        "outputId": "c5bbf770-440c-4ecb-c615-0bb852de5d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 24 02:29:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5xW2dVmQzBV",
        "outputId": "927b3b67-a908-4867-ebdf-ba4c943ab181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1doFTTNNYPcd",
        "outputId": "3de33bdb-7146-4300-b8bc-78af4a441997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow_datasets) (3.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.54.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6PYidFDYZ7d"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462,
          "referenced_widgets": [
            "69dbabd3bbb14d41b543d73be96be9de",
            "3946837815ac412caf8da7b4039c3d69",
            "a1d7ec239c0f46c797cd4d419e7f4ab1",
            "1d36a664f77d4976abeab552a204d350",
            "8a006ce4827a489a83b7fdd7ce11a82d",
            "b831e575287849c9a157e31fc3f9e687",
            "c8405a87310f4747b342e0839d26ed2b",
            "0e07757635634f4ba96bbb96dc2b42c8",
            "b4cf3196f4854f43bfb9b05536453fe3",
            "6fb1d31ea63d4c99a250181af6b89d3b",
            "a246523def8d4ab0b08e16c3db43e75e",
            "6ea0203fa460498aadb0dd0330234b31",
            "9f198be369eb46be98bf48291b2add95",
            "11e9f89872054da8b44cdeeff50af318",
            "39fe640a8aed44e185c00433f9f55f7f",
            "6b7282b2ef964fd4b3b5978a0828dc1c",
            "25afdc4662604f9d966d310a43e12c3a",
            "30eb132c26a74c45847ed58fa3d39b5b",
            "33c1b635d8fe42229c68cfdbf1a60654",
            "22832c078a34499589b0dc22e66f9ef9",
            "e6a66d18837d422caf700c71ddd893b2",
            "372f00e1efaa4160a3fa7617c8232beb",
            "8d8c0366996d41c29dbbbec11ea8406d",
            "75bb174f23874d2494c67977bdc09b86",
            "34012c579a42402daf910baef907cd53",
            "a7d2918e086448fd803db6aa4eb71bf7",
            "aa127aa81d1a4e28b6fb6507c6d3d8ac",
            "ac3e0b7dcd49416ea91b31de1669f9bd",
            "1e48b0c1e0b342fabed5f2b3d215098b",
            "8f8545531efc4547a3214cf030554a23",
            "96a5f4e2e0274d7085846dc17eefcb4a",
            "0a169d67dcfd4b2faca59d0fa173c85f",
            "18ed446013894f248a36eeaf0f8bc8fc"
          ]
        },
        "id": "60Amtmy3Yw6p",
        "outputId": "4cdd04a1-9b1f-4c4d-d5bb-293995d20299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset cnn_dailymail/plain_text/3.0.0 (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0...\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69dbabd3bbb14d41b543d73be96be9de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ea0203fa460498aadb0dd0330234b31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d8c0366996d41c29dbbbec11ea8406d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "DownloadError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-09eb0ffd5583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_dailymail'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    385\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    386\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m   1023\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m         prepare_split_kwargs)\n\u001b[1;32m    961\u001b[0m     for split_generator in self._split_generators(\n\u001b[0;32m--> 962\u001b[0;31m         dl_manager, **split_generators_kwargs):\n\u001b[0m\u001b[1;32m    963\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/summarization/cnn_dailymail.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mdl_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DL_URLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_subset_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# Generate shared vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    634\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    634\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36m_target_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# type: (bool) -> Any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36m_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mraise_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36mhandle_future_result\u001b[0;34m(future)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# type: (Any) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/downloader.py\u001b[0m in \u001b[0;36m_sync_download\u001b[0;34m(self, url, destination_path)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m       \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/downloader.py\u001b[0m in \u001b[0;36m_open_with_requests\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_drive_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m       \u001b[0m_assert_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/download/downloader.py\u001b[0m in \u001b[0;36m_assert_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     raise DownloadError('Failed to get url {}. HTTP code: {}.'.format(\n\u001b[0;32m--> 259\u001b[0;31m         response.url, response.status_code))\n\u001b[0m",
            "\u001b[0;31mDownloadError\u001b[0m: Failed to get url https://doc-0g-5k-docs.googleusercontent.com/docs/securesc/rsa1hgg4mk4h151bsofrrm22tbfhvja8/39e4ujkqpm2unpuqjg678pl2cqo65643/1642991325000/00708016728989131340/06275965708547574969Z/0BwmD_VLjROrfTHk4NFg2SndKcjQ?e=download&nonce=ogiksdd9rve76&user=06275965708547574969Z&hash=tckhco9qvm6ie7od0hehmkav6v3q4kkp. HTTP code: 403."
          ]
        }
      ],
      "source": [
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load('cnn_dailymail', split = ['train', 'validation', 'test'], with_info = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUW9LURMY04L"
      },
      "outputs": [],
      "source": [
        "df_train = tfds.as_dataframe(ds_train.take(-1), ds_info)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnu3LGzDY5Bn"
      },
      "outputs": [],
      "source": [
        "df_val = tfds.as_dataframe(ds_validation.take(-1), ds_info)\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpPWymomY8it"
      },
      "outputs": [],
      "source": [
        "df_test = tfds.as_dataframe(ds_test.take(-1), ds_info)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yej9PdLQY_5w"
      },
      "outputs": [],
      "source": [
        "def decode_text(x):\n",
        "    return x.decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TQIrskDZERh"
      },
      "outputs": [],
      "source": [
        "df_train.loc[:, 'article'] = df_train.loc[:, 'article'].progress_apply(decode_text)\n",
        "df_train.loc[:, 'highlights'] = df_train.loc[:, 'highlights'].progress_apply(decode_text)\n",
        "df_val.loc[:, 'article'] = df_val.loc[:, 'article'].progress_apply(decode_text)\n",
        "df_val.loc[:, 'highlights'] = df_val.loc[:, 'highlights'].progress_apply(decode_text)\n",
        "df_test.loc[:, 'article'] = df_test.loc[:, 'article'].progress_apply(decode_text)\n",
        "df_test.loc[:, 'highlights'] = df_test.loc[:, 'highlights'].progress_apply(decode_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq6V5bZUSMlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77525f0-c5d9-412b-bb70-7c43311703cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4atwxEtZGtW"
      },
      "outputs": [],
      "source": [
        "import os, string, re, json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import wordpunct_tokenize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Embedding, Concatenate, TimeDistributed, RNN, LSTMCell, AdditiveAttention, GRU, LSTM\n",
        "from tensorflow.keras.backend import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Loss, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f47WF8ALZM-Q"
      },
      "outputs": [],
      "source": [
        "def length(x):\n",
        "    return len(wordpunct_tokenize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRRqQ6rYZRa9"
      },
      "outputs": [],
      "source": [
        "df_train['Article_Length'] = df_train['article'].progress_apply(length)\n",
        "df_train['Summary_Length'] = df_train['highlights'].progress_apply(length)\n",
        "df_val['Article_Length'] = df_val['article'].progress_apply(length)\n",
        "df_val['Summary_Length'] = df_val['highlights'].progress_apply(length)\n",
        "df_test['Article_Length'] = df_test['article'].progress_apply(length)\n",
        "df_test['Summary_Length'] = df_test['highlights'].progress_apply(length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ3O_ZxhZTsl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (13, 9))\n",
        "sns.distplot(df_train['Article_Length'], color = 'red', label = 'Article Length')\n",
        "sns.distplot(df_train['Summary_Length'], color = 'blue', label = 'Summary Length')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYgyFB9nZXXY"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_train['Article_Length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySvrQhZaZh48"
      },
      "outputs": [],
      "source": [
        "df_train['Article_Length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l7cUGsSZklO"
      },
      "outputs": [],
      "source": [
        "np.percentile(df_train['Article_Length'], 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHa6lNGhZnci"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_train['Summary_Length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJaMGTpMZqGi"
      },
      "outputs": [],
      "source": [
        "df_train['Summary_Length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "xfiyQUilZtix",
        "outputId": "46ef608a-4db2-44ed-a691-50197ad4e3cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-114212cf983f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Summary_Length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "np.percentile(df_train['Summary_Length'], 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTFbYw4rYBrF"
      },
      "outputs": [],
      "source": [
        "df_train.drop(df_train[df_train['Article_Length'] > 548].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvXhxAK5-DhK"
      },
      "outputs": [],
      "source": [
        "df_val.drop(df_val[df_val['Article_Length'] > 548].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXYv9r6SJQrU"
      },
      "outputs": [],
      "source": [
        "df_test.drop(df_test[df_test['Article_Length'] > 548].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1z9yje4Yx-8",
        "outputId": "fde94849-517c-41ca-981b-942bff7a5737"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    80496.000000\n",
              "mean       399.271430\n",
              "std        102.898796\n",
              "min         11.000000\n",
              "25%        328.000000\n",
              "50%        415.000000\n",
              "75%        485.000000\n",
              "max        548.000000\n",
              "Name: Article_Length, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df_train['Article_Length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRx4XXE-Y5Nk",
        "outputId": "70d7de97-2a87-4817-bdf9-bfecf1ef1421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    80496.000000\n",
              "mean        49.380454\n",
              "std         19.551554\n",
              "min          6.000000\n",
              "25%         39.000000\n",
              "50%         47.000000\n",
              "75%         58.000000\n",
              "max       1982.000000\n",
              "Name: Summary_Length, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df_train['Summary_Length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIRcdpqLZHkT",
        "outputId": "d857e3b8-bd77-4376-ccc4-fad2e72eb861"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "498.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "np.percentile(df_train['Article_Length'], 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJBlNN28ZwPJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(free_text):\n",
        "    # remove non-word characters    \n",
        "    ft = free_text.strip()\n",
        "    tokens = wordpunct_tokenize(ft)\n",
        "    tokens.append('_END_')\n",
        "    tokens.insert(0, '_START_')\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CNdYq3YKFP2",
        "outputId": "ecb674fd-e956-4add-8f10-c953168bdd27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80496, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM8ZbNyMKPLx",
        "outputId": "120ad175-b0fd-4c73-a9bf-d488ba5c1e4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4254, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HO3Ryq_JmSS",
        "outputId": "bdca01a1-72b2-41db-e565-a71cc17be024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3605, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mIRaOjd5KRtK",
        "outputId": "b72080f2-2971-4a69-85a6-064cbef427a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c23bb2aa-3ad2-465b-9c29-8ea298da54bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "      <th>Article_Length</th>\n",
              "      <th>Summary_Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fears are growing that Britain's jails are bec...</td>\n",
              "      <td>Increasing Muslim prison population highlighte...</td>\n",
              "      <td>464</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>By . Ted Thornhill . Last updated at 2:18 PM o...</td>\n",
              "      <td>The free iPhone app comes with a 'missile stri...</td>\n",
              "      <td>399</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>The secret to staying slim could be in saliva....</td>\n",
              "      <td>AMY1 gene makes a carb-busting compound and ca...</td>\n",
              "      <td>428</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(CNN) -- Virgin, a leading branded venture cap...</td>\n",
              "      <td>The Virgin Group was founded by Richard Branso...</td>\n",
              "      <td>220</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Andy Murray appeared simply delighted on Chris...</td>\n",
              "      <td>Andy Murray takes to Twitter to show off his n...</td>\n",
              "      <td>306</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c23bb2aa-3ad2-465b-9c29-8ea298da54bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c23bb2aa-3ad2-465b-9c29-8ea298da54bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c23bb2aa-3ad2-465b-9c29-8ea298da54bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              article  ... Summary_Length\n",
              "2   Fears are growing that Britain's jails are bec...  ...             45\n",
              "6   By . Ted Thornhill . Last updated at 2:18 PM o...  ...             17\n",
              "11  The secret to staying slim could be in saliva....  ...             54\n",
              "14  (CNN) -- Virgin, a leading branded venture cap...  ...             39\n",
              "17  Andy Murray appeared simply delighted on Chris...  ...             57\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "full_df = pd.concat([df_train, df_val, df_test])\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8b3Ot_FKYFA",
        "outputId": "487ef732-dbde-4bfc-a786-282c3fedb9ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88355, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "full_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Y7ABnxaixR",
        "outputId": "69d81368-c063-45b2-8201-1b196a13479d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 88355/88355 [00:10<00:00, 8589.68it/s]\n",
            "100%|██████████| 88355/88355 [00:01<00:00, 63906.10it/s]\n"
          ]
        }
      ],
      "source": [
        "full_df['preprocessed_articles'] = full_df['article'].progress_apply(preprocess_text)\n",
        "full_df['preprocessed_summaries'] = full_df['highlights'].progress_apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flPX0MC6azok"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(full_df['preprocessed_articles'].tolist() + full_df['preprocessed_articles'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Mu0QjX11xM"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_features = vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIt5zu3TVVga",
        "outputId": "13cc366f-4550-4f41-89bb-0d1750bbffa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195818"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e6OMGNjCELA"
      },
      "outputs": [],
      "source": [
        "# Create vocabulary using tokenizer's assigned indices to words\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzDlpw5HCcj3"
      },
      "outputs": [],
      "source": [
        "embed_size = 192\n",
        "maxlen_article = 550\n",
        "maxlen_summary = 50\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_87ZHimRLRRT"
      },
      "outputs": [],
      "source": [
        "training_articles, validation_articles, training_summaries, validation_summaries = train_test_split(full_df[['article', 'preprocessed_articles']], full_df[['highlights', 'preprocessed_summaries']], test_size = 0.1, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpSOuv55NBFW",
        "outputId": "d6164850-946a-4864-aff0-a79ee50c8bf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56690     South Africa have returned to the top of the R...\n",
              "20071     Three members of a Russian feminist punk band ...\n",
              "227399    (EW.com) -- Matt Smith of \"Doctor Who\" fame wi...\n",
              "280663    By . Steve Robson . PUBLISHED: . 05:02 EST, 12...\n",
              "256874    Los Angeles, California (CNN) -- Nancy Dolman,...\n",
              "Name: article, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "training_articles['article'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9we47q-NF-0",
        "outputId": "62551cac-e47e-4c19-c0e9-6158d1b0cefd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56690     South Africa No 1 in ICC ODI rankings for firs...\n",
              "20071     Band face seven years in jail if found guilty ...\n",
              "227399    Former \"Doctor Who\" star Matt Smith is confirm...\n",
              "280663    Shalema Gaskin shot outside Brookdale Universi...\n",
              "256874    Martin Short's representative would not releas...\n",
              "Name: highlights, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "training_summaries['highlights'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtcC5-uxPzM5"
      },
      "outputs": [],
      "source": [
        "datapath = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re-Ibvc0J832"
      },
      "outputs": [],
      "source": [
        "training_articles.to_csv(datapath + 'training_articles.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbw2Pu8JKOwa"
      },
      "outputs": [],
      "source": [
        "training_summaries.to_csv(datapath + 'training_summaries.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vIRqoO6KTDT"
      },
      "outputs": [],
      "source": [
        "validation_articles.to_csv(datapath + 'validation_articles.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAJ1GFSgKW5O"
      },
      "outputs": [],
      "source": [
        "validation_summaries.to_csv(datapath + 'validation_summaries.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-w8-pSCvPoJ"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/text_summarizer_models/no_glove/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qgETAPECfNG"
      },
      "outputs": [],
      "source": [
        "train_article_sequences = tokenizer.texts_to_sequences(training_articles['preprocessed_articles'].tolist())\n",
        "train_summary_sequences = tokenizer.texts_to_sequences(training_summaries['preprocessed_summaries'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApkN53Z2LvYk"
      },
      "outputs": [],
      "source": [
        "validation_article_sequences = tokenizer.texts_to_sequences(validation_articles['preprocessed_articles'].tolist())\n",
        "validation_summary_sequences = tokenizer.texts_to_sequences(validation_summaries['preprocessed_summaries'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-ZllH--e3kK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y_%H:_%M:_%S\")\n",
        "with open(filepath + 'tokenizer_' + dt_string +'.pickle', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f, protocol = pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uU8QkK_CkAR"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(train_article_sequences, maxlen = maxlen_article, padding = 'post')\n",
        "y_train = pad_sequences(train_summary_sequences, maxlen = maxlen_summary, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vi34upALqo_"
      },
      "outputs": [],
      "source": [
        "X_val = pad_sequences(validation_article_sequences, maxlen = maxlen_article, padding = 'post')\n",
        "y_val = pad_sequences(validation_summary_sequences, maxlen = maxlen_summary, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFzrAuTLCp0F",
        "outputId": "df6f4a83-6e8a-411a-89b3-09c7863933c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79519, 550)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViLbgfVEMHbL",
        "outputId": "e7c5eab5-4938-4229-8f6a-30b0e0e034c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8836, 550)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF3HLn4fhZlh"
      },
      "source": [
        "## Text Summarizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF_wQB9XAq-T"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = Embedding(self.input_vocab_size, embedding_dim, embeddings_initializer = 'glorot_normal')\n",
        "\n",
        "        # The GRU RNN layer processes those vectors sequentially.\n",
        "\n",
        "        self.lstm1 = LSTM(128, return_sequences=True, \n",
        "                     return_state=True)\n",
        "\n",
        "        # self.lstm2 = LSTM(128, return_sequences=True,\n",
        "        #              return_state=True)\n",
        "    \n",
        "        # self.lstm3 = LSTM(128, return_sequences=True,\n",
        "        #              return_state=True)\n",
        "\n",
        "    def call(self, tokens, state=None):\n",
        "    \n",
        "        # 2. The embedding layer looks up the embedding for each token.\n",
        "        vectors = self.embedding(tokens)\n",
        "\n",
        "        # 3. The GRU processes the embedding sequence.\n",
        "        #    output shape: (batch, s, enc_units)\n",
        "        #    state shape: (batch, enc_units)\n",
        "        output_1, state_h1, state_c1  = self.lstm1(vectors)\n",
        "        # output_2, state_h2, state_c2 = self.lstm2(output_1)\n",
        "        # output_3, state_h3, state_c3 = self.lstm3(output_2)\n",
        "        # 4. Returns the new sequence and its state.\n",
        "        # return output_3, state_h3\n",
        "        # return output_2, state_h2\n",
        "        return output_1, state_h1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3TNTnFm2ODS"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJf5ZZ74gruU"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxTgV-jYA3TJ"
      },
      "outputs": [],
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # For Step 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = Embedding(self.output_vocab_size, embedding_dim, embeddings_initializer = 'glorot_normal')\n",
        "\n",
        "        # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # For step 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "        # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "        self.Wc = Dense(dec_units, activation=tf.keras.activations.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "        # For step 5. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.fc = Dense(self.output_vocab_size)\n",
        "    \n",
        "    def call(self, inputs: DecoderInput, state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "\n",
        "        # Step 1. Lookup the embeddings\n",
        "        vectors = self.embedding(inputs.new_tokens)\n",
        "    \n",
        "        # Step 2. Process one step with the RNN\n",
        "        rnn_output, state, carry_state = self.lstm(vectors)\n",
        "\n",
        "        # Step 3. Use the RNN output as the query for the attention over the\n",
        "        # encoder output.\n",
        "        context_vector, attention_weights = self.attention(query = rnn_output, value = inputs.enc_output, mask = inputs.mask)\n",
        "\n",
        "        # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "        #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "        context_and_rnn_output = tf.concat([context_vector, rnn_output], axis = -1)\n",
        "\n",
        "        # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "        attention_vector = self.Wc(context_and_rnn_output)\n",
        "        \n",
        "        # Step 5. Generate logit predictions:\n",
        "        logits = self.fc(attention_vector)\n",
        "\n",
        "        return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D0DJW5Lts07"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(Loss):\n",
        "    def __init__(self):\n",
        "        self.name = 'masked_loss'\n",
        "        self.loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        # Calculate the loss for each item in the batch.\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "    \n",
        "        # Mask off the losses on padding.\n",
        "        mask = tf.cast(y_true != 0, tf.float32)\n",
        "        loss *= mask\n",
        "\n",
        "        # Return the total.\n",
        "        return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-znrarH29Kd"
      },
      "outputs": [],
      "source": [
        "class TextSummarizerModel(Model):\n",
        "    def __init__(self, (), use_tf_function=True):\n",
        "        super(TextSummarizerModel, self).__init__()\n",
        "        self.encoder = Encoder(vocab_size, embed_size)\n",
        "        self.decoder = Decoder(vocab_size, embed_size, 128)\n",
        "        self.use_tf_function = use_tf_function\n",
        "\n",
        "    def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "        input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "        # Run the decoder one step.\n",
        "        decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "        # print('Entered Decoder')\n",
        "        dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "        # print('Exit Decoder')\n",
        "        # `self.loss` returns the total for non-padded tokens\n",
        "        y = target_token\n",
        "        y_pred = dec_result.logits\n",
        "        step_loss = self.loss(y, y_pred)\n",
        "        # print('Exit Loop Decoder')\n",
        "        return step_loss, dec_state\n",
        "\n",
        "    def get_masks(self, input_tokens, target_tokens):\n",
        "        return (input_tokens != 0), (target_tokens != 0)\n",
        "\n",
        "    def test_step(self, inputs):\n",
        "        max_target_length = maxlen_summary\n",
        "        X, y = inputs\n",
        "        input_mask, target_mask = self.get_masks(X, y)\n",
        "        enc_output, enc_state = self.encoder(X)\n",
        "        dec_state = enc_state\n",
        "        loss = tf.constant(0.0)\n",
        "        for t in tf.range(max_target_length - 1):\n",
        "            new_tokens = y[:, i:i+2]\n",
        "            step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "            loss = loss + step_loss\n",
        "        \n",
        "        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "        return {'average_loss': average_loss}\n",
        "\n",
        "    def _train_step(self, input_tokens, target_tokens):\n",
        "        max_target_length = maxlen_summary\n",
        "\n",
        "        steps_per_epoch = X_train.shape[0] // batch_size\n",
        "\n",
        "        for i in tf.range(steps_per_epoch):\n",
        "\n",
        "            batch_inputs = input_tokens[i * batch_size: (i + 1) * batch_size, :]\n",
        "            batch_outputs = target_tokens[i * batch_size: (i + 1) * batch_size, :]\n",
        "\n",
        "            input_mask, target_mask = self.get_masks(batch_inputs, batch_outputs)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Encode the input\n",
        "                enc_output, enc_state = self.encoder(batch_inputs)\n",
        "\n",
        "                # Initialize the decoder's state to the encoder's final state.\n",
        "                # This only works if the encoder and decoder have the same number of\n",
        "                # units.\n",
        "                dec_state = enc_state\n",
        "                loss = tf.constant(0.0)\n",
        "\n",
        "                for t in tf.range(max_target_length - 1):\n",
        "                    # Pass in two tokens from the target sequence:\n",
        "                    # 1. The current input to the decoder.\n",
        "                    # 2. The target for the decoder's next prediction.\n",
        "                    new_tokens = batch_outputs[:, t:t+2]\n",
        "                    step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "                    loss = loss + step_loss\n",
        "\n",
        "                # Average the loss over all non padding tokens.\n",
        "                average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "            # Apply an optimization step\n",
        "            variables = self.trainable_variables\n",
        "            gradients = tape.gradient(average_loss, variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "            # Return a dict mapping metric names to current value\n",
        "            # print('Batch {}: Loss = {}'.format(i, average_loss))\n",
        "            # print('Time Taken for batch: {}s'.format(time.time() - start_time))\n",
        "            return {'batch_loss': average_loss}\n",
        "\n",
        "    @tf.function\n",
        "    def _tf_train_step(self, input_tokens, output_tokens):\n",
        "        # print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "        return self._train_step(input_tokens, output_tokens)\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "        input_tokens, output_tokens = inputs\n",
        "        if self.use_tf_function:\n",
        "            return self._tf_train_step(input_tokens, output_tokens)\n",
        "        else:\n",
        "            return self._train_step(input_tokens, output_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2zSevmMxUKj"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.logs = []\n",
        "\n",
        "    def on_train_batch_end(self, n, logs):\n",
        "        self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgA17jgWxEKn"
      },
      "outputs": [],
      "source": [
        "model = TextSummarizerModel()\n",
        "# Configure the loss and optimizer\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = MaskedLoss())\n",
        "\n",
        "# model.evaluate(X_train[:1, :], y_train[:1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V4NnoGS_mlt",
        "outputId": "b997a97d-357b-4b3e-e7db-15a423a5a438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "ckpt_filepath = '/content/drive/MyDrive/text_summarizer_models/no_glove/model_checkpoint_weights_'+ dt_string +'_{epoch:02d}.h5'\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "\tckpt_filepath,\n",
        "\tperiod=1,\n",
        "\tmonitor=\"batch_loss\",\n",
        "\tverbose=0,\n",
        "\tsave_best_only=False,\n",
        "\tsave_weights_only=True,\n",
        "\tmode=\"auto\",\n",
        "\tsave_freq=\"epoch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylVEgNeIy6gh",
        "outputId": "c8bd5689-3767-41d5-b582-6b28d6faa607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1045/2485 [===========>..................] - ETA: 28:49 - batch_loss: 7.0715"
          ]
        }
      ],
      "source": [
        "# model.build(input_shape = (None, maxlen_article))\n",
        "model.fit(X_train, y_train, epochs = 2, callbacks=[batch_loss, callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCFuMdAHM56C"
      },
      "outputs": [],
      "source": [
        "model.save_weights(filepath + 'final_model_weights_' + dt_string + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx8-h6tayIv1"
      },
      "source": [
        "### Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xla7hMDVnPb"
      },
      "outputs": [],
      "source": [
        "class Summarizer(tf.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.output_token_string_from_index = (tf.keras.layers.StringLookup(\n",
        "            vocabulary = list(word_index.keys()),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "        # The output should never generate padding, unknown, or start.\n",
        "        index_from_string = tf.keras.layers.StringLookup(vocabulary = list(word_index.keys()), mask_token='')\n",
        "        token_mask_ids = index_from_string(['', '_START_', '_END_']).numpy()\n",
        "        token_mask = np.zeros([vocab_size], dtype=np.bool)\n",
        "        token_mask[np.array(token_mask_ids)] = True\n",
        "        self.token_mask = token_mask\n",
        "        self.start_token = index_from_string(tf.constant('_START_'))\n",
        "        self.end_token = index_from_string(tf.constant('_END_'))\n",
        "    \n",
        "    def tokens_to_text(self, result_tokens):\n",
        "        result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "        \n",
        "        result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "\n",
        "        result_text = tf.strings.strip(result_text)\n",
        "        return result_text\n",
        "\n",
        "    def sample(self, logits, temperature):\n",
        "        token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  \n",
        "        # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "        logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "        if temperature == 0.0:\n",
        "            new_tokens = tf.argmax(logits, axis=-1)\n",
        "        else: \n",
        "            logits = tf.squeeze(logits, axis=1)\n",
        "        \n",
        "        new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "        return new_tokens\n",
        "\n",
        "    def abstractive_summarize(self, input_tokens, *, max_length=maxlen_article, return_attention=True, temperature=1.0):\n",
        "        batch_size = tf.shape(input_tokens)[0]\n",
        "        enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "        result_tokens = []\n",
        "        attention = []\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "            dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "            attention.append(dec_result.attention_weights)\n",
        "\n",
        "            new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "            # If a sequence produces an `end_token`, set it `done`\n",
        "            done = done | (new_tokens == self.end_token)\n",
        "            # Once a sequence is done it only produces 0-padding.\n",
        "            new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "            # Collect the generated tokens\n",
        "            result_tokens.append(new_tokens)\n",
        "\n",
        "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "                break\n",
        "\n",
        "        # Convert the list of generates token ids to a list of strings.\n",
        "        result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "        result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "        if return_attention:\n",
        "            attention_stack = tf.concat(attention, axis=1)\n",
        "            return {'text': result_text, 'attention': attention_stack}\n",
        "        else:\n",
        "            return {'text': result_text}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(dtype=tf.int32, shape=[None, maxlen_article])])\n",
        "    def tf_summarize(self, input_tokens):\n",
        "        return self.abstractive_summarize(input_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSlPvCpBW-q6"
      },
      "outputs": [],
      "source": [
        "summarizer = Summarizer(encoder = model.encoder, decoder = model.decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzeHqc2wZ7as",
        "outputId": "4dacf6e7-ace7-46ef-9619-8881ee5d02f9"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-119-e39eb835cf98>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    signatures={'serving_default': summarizer.tf_summarize}\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(summarizer, filepath + 'summarizer',\n",
        "                    signatures={'serving_default': summarizer.tf_summarize})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcbO733GyA_K"
      },
      "outputs": [],
      "source": [
        "summarizer.tf_summarize(X_val[:5, :])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CNN DailyMail Text Summarization (No GLoVe + Bahdanau only) Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69dbabd3bbb14d41b543d73be96be9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3946837815ac412caf8da7b4039c3d69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1d7ec239c0f46c797cd4d419e7f4ab1",
              "IPY_MODEL_1d36a664f77d4976abeab552a204d350",
              "IPY_MODEL_8a006ce4827a489a83b7fdd7ce11a82d"
            ]
          }
        },
        "3946837815ac412caf8da7b4039c3d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1d7ec239c0f46c797cd4d419e7f4ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b831e575287849c9a157e31fc3f9e687",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Completed...:  40%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8405a87310f4747b342e0839d26ed2b"
          }
        },
        "1d36a664f77d4976abeab552a204d350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e07757635634f4ba96bbb96dc2b42c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4cf3196f4854f43bfb9b05536453fe3"
          }
        },
        "8a006ce4827a489a83b7fdd7ce11a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fb1d31ea63d4c99a250181af6b89d3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/5 [00:01&lt;00:01,  2.76 url/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a246523def8d4ab0b08e16c3db43e75e"
          }
        },
        "b831e575287849c9a157e31fc3f9e687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8405a87310f4747b342e0839d26ed2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e07757635634f4ba96bbb96dc2b42c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4cf3196f4854f43bfb9b05536453fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fb1d31ea63d4c99a250181af6b89d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a246523def8d4ab0b08e16c3db43e75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ea0203fa460498aadb0dd0330234b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f198be369eb46be98bf48291b2add95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11e9f89872054da8b44cdeeff50af318",
              "IPY_MODEL_39fe640a8aed44e185c00433f9f55f7f",
              "IPY_MODEL_6b7282b2ef964fd4b3b5978a0828dc1c"
            ]
          }
        },
        "9f198be369eb46be98bf48291b2add95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11e9f89872054da8b44cdeeff50af318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25afdc4662604f9d966d310a43e12c3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Size...: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30eb132c26a74c45847ed58fa3d39b5b"
          }
        },
        "39fe640a8aed44e185c00433f9f55f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33c1b635d8fe42229c68cfdbf1a60654",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22832c078a34499589b0dc22e66f9ef9"
          }
        },
        "6b7282b2ef964fd4b3b5978a0828dc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6a66d18837d422caf700c71ddd893b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/0 [00:01&lt;00:00,  1.34 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_372f00e1efaa4160a3fa7617c8232beb"
          }
        },
        "25afdc4662604f9d966d310a43e12c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30eb132c26a74c45847ed58fa3d39b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33c1b635d8fe42229c68cfdbf1a60654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22832c078a34499589b0dc22e66f9ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6a66d18837d422caf700c71ddd893b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "372f00e1efaa4160a3fa7617c8232beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d8c0366996d41c29dbbbec11ea8406d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_75bb174f23874d2494c67977bdc09b86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34012c579a42402daf910baef907cd53",
              "IPY_MODEL_a7d2918e086448fd803db6aa4eb71bf7",
              "IPY_MODEL_aa127aa81d1a4e28b6fb6507c6d3d8ac"
            ]
          }
        },
        "75bb174f23874d2494c67977bdc09b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34012c579a42402daf910baef907cd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac3e0b7dcd49416ea91b31de1669f9bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Extraction completed...: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e48b0c1e0b342fabed5f2b3d215098b"
          }
        },
        "a7d2918e086448fd803db6aa4eb71bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f8545531efc4547a3214cf030554a23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96a5f4e2e0274d7085846dc17eefcb4a"
          }
        },
        "aa127aa81d1a4e28b6fb6507c6d3d8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a169d67dcfd4b2faca59d0fa173c85f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/0 [00:00&lt;?, ? file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18ed446013894f248a36eeaf0f8bc8fc"
          }
        },
        "ac3e0b7dcd49416ea91b31de1669f9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e48b0c1e0b342fabed5f2b3d215098b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f8545531efc4547a3214cf030554a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96a5f4e2e0274d7085846dc17eefcb4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a169d67dcfd4b2faca59d0fa173c85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18ed446013894f248a36eeaf0f8bc8fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}